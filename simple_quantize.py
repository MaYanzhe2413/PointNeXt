#!/usr/bin/env python3
"""
ç®€åŒ–ç‰ˆ PointNeXt é‡åŒ–è„šæœ¬
ç›´æ¥ä»é…ç½®æ–‡ä»¶æ„å»ºæ¨¡å‹å¹¶è¿›è¡Œé‡åŒ–ï¼Œé¿å…å¤æ‚çš„é…ç½®è§£æ
"""

import os
import sys
import torch
import torch.nn as nn
import yaml
import argparse
from pathlib import Path

# æ·»åŠ è·¯å¾„
sys.path.append('openpoints')

def simple_quantize_pointnext(config_file, pretrained_path=None, output_path=None):
    """
    ç®€åŒ–çš„PointNeXté‡åŒ–å‡½æ•°
    
    Args:
        config_file: é…ç½®æ–‡ä»¶è·¯å¾„ 
        pretrained_path: é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„
        output_path: è¾“å‡ºè·¯å¾„
    """
    
    print("ğŸš€ å¼€å§‹ç®€åŒ–é‡åŒ–æµç¨‹")
    print(f"ğŸ“ é…ç½®æ–‡ä»¶: {config_file}")
    print(f"ğŸ’¾ é¢„è®­ç»ƒæ¨¡å‹: {pretrained_path if pretrained_path else 'æ— '}")
    
    # 1. ç›´æ¥å¯¼å…¥å’Œæ„å»ºæ¨¡å‹
    try:
        from openpoints.models import build_model_from_cfg
        from openpoints.utils import EasyConfig
        
        # åŠ è½½é…ç½®
        cfg = EasyConfig()
        cfg.load(config_file)
        
        # æ„å»ºæ¨¡å‹
        print("ğŸ—ï¸  æ„å»ºæ¨¡å‹...")
        model = build_model_from_cfg(cfg.model)
        
        # åŠ è½½é¢„è®­ç»ƒæƒé‡
        if pretrained_path and os.path.exists(pretrained_path):
            print(f"ğŸ“¥ åŠ è½½é¢„è®­ç»ƒæƒé‡...")
            checkpoint = torch.load(pretrained_path, map_location='cpu')
            
            # å¤„ç†ä¸åŒçš„checkpointæ ¼å¼
            if 'model' in checkpoint:
                state_dict = checkpoint['model']
            elif 'state_dict' in checkpoint:
                state_dict = checkpoint['state_dict']
            else:
                state_dict = checkpoint
            
            # åŠ è½½æƒé‡ (å¿½ç•¥ä¸åŒ¹é…çš„é”®)
            model.load_state_dict(state_dict, strict=False)
            print("âœ… æƒé‡åŠ è½½å®Œæˆ")
            
        model.eval()
        print(f"âœ… æ¨¡å‹æ„å»ºå®Œæˆ")
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹æ„å»ºå¤±è´¥: {e}")
        return None
    
    # 2. åˆ›å»ºç¤ºä¾‹è¾“å…¥
    print("ğŸ“Š åˆ›å»ºæ ¡å‡†æ•°æ®...")
    
    def create_sample_input():
        """åˆ›å»ºç¤ºä¾‹è¾“å…¥æ•°æ®"""
        batch_size = 1
        num_points = 1024
        
        # åˆ›å»ºç‚¹äº‘æ•°æ®
        pos = torch.randn(batch_size, num_points, 3)
        features = torch.randn(batch_size, num_points, 3)  # RGBç‰¹å¾
        
        # æ„å»ºè¾“å…¥å­—å…¸
        sample_input = {
            'pos': pos,
            'x': features
        }
        
        return sample_input
    
    sample_input = create_sample_input()
    
    # 3. æµ‹è¯•æ¨¡å‹å‰å‘ä¼ æ’­
    print("ğŸ§ª æµ‹è¯•æ¨¡å‹å‰å‘ä¼ æ’­...")
    try:
        with torch.no_grad():
            original_output = model(sample_input)
        print("âœ… å‰å‘ä¼ æ’­æµ‹è¯•æˆåŠŸ")
    except Exception as e:
        print(f"âŒ å‰å‘ä¼ æ’­å¤±è´¥: {e}")
        return None
    
    # 4. ä½¿ç”¨é™æ€é‡åŒ–
    print("ğŸ”¥ å¼€å§‹é™æ€é‡åŒ–...")
    
    # è®¾ç½®é‡åŒ–é…ç½®
    model.qconfig = torch.quantization.get_default_qconfig('fbgemm')
    
    # é€’å½’è®¾ç½®å­æ¨¡å—çš„é‡åŒ–é…ç½®
    def set_qconfig_recursive(module):
        for name, child in module.named_children():
            if hasattr(child, 'qconfig'):
                child.qconfig = torch.quantization.get_default_qconfig('fbgemm')
            set_qconfig_recursive(child)
    
    set_qconfig_recursive(model)
    
    # å‡†å¤‡é‡åŒ–
    print("âš™ï¸  å‡†å¤‡é‡åŒ–...")
    try:
        model_prepared = torch.quantization.prepare(model)
        print("âœ… é‡åŒ–å‡†å¤‡å®Œæˆ")
    except Exception as e:
        print(f"âŒ é‡åŒ–å‡†å¤‡å¤±è´¥: {e}")
        return None
    
    # æ ¡å‡†ï¼ˆä½¿ç”¨å¤šä¸ªæ ·æœ¬ï¼‰
    print("ğŸ“ˆ å¼€å§‹æ ¡å‡†...")
    model_prepared.eval()
    
    with torch.no_grad():
        for i in range(10):  # ä½¿ç”¨10ä¸ªæ ·æœ¬è¿›è¡Œæ ¡å‡†
            try:
                # åˆ›å»ºä¸åŒçš„æ ¡å‡†æ ·æœ¬
                cal_input = create_sample_input()
                _ = model_prepared(cal_input)
            except Exception as e:
                print(f"âš ï¸  æ ¡å‡†æ ·æœ¬ {i} å¤±è´¥: {e}")
                continue
    
    print("âœ… æ ¡å‡†å®Œæˆ")
    
    # è½¬æ¢ä¸ºé‡åŒ–æ¨¡å‹
    print("ğŸ”„ è½¬æ¢ä¸ºé‡åŒ–æ¨¡å‹...")
    try:
        quantized_model = torch.quantization.convert(model_prepared)
        print("âœ… é‡åŒ–è½¬æ¢æˆåŠŸ")
    except Exception as e:
        print(f"âŒ é‡åŒ–è½¬æ¢å¤±è´¥: {e}")
        return None
    
    # 5. éªŒè¯é‡åŒ–æ¨¡å‹
    print("ğŸ§ª éªŒè¯é‡åŒ–æ¨¡å‹...")
    try:
        with torch.no_grad():
            quantized_output = quantized_model(sample_input)
        print("âœ… é‡åŒ–æ¨¡å‹éªŒè¯æˆåŠŸ")
    except Exception as e:
        print(f"âŒ é‡åŒ–æ¨¡å‹éªŒè¯å¤±è´¥: {e}")
        return None
    
    # 6. æ€§èƒ½å¯¹æ¯”
    print("ğŸ“Š æ€§èƒ½å¯¹æ¯”...")
    
    def measure_inference_time(model, input_data, num_runs=50):
        """æµ‹é‡æ¨ç†æ—¶é—´"""
        model.eval()
        total_time = 0
        
        with torch.no_grad():
            # é¢„çƒ­
            for _ in range(5):
                _ = model(input_data)
            
            # æ­£å¼æµ‹é‡
            import time
            for _ in range(num_runs):
                start_time = time.time()
                _ = model(input_data)
                total_time += time.time() - start_time
        
        return (total_time / num_runs) * 1000  # è¿”å›æ¯«ç§’
    
    def get_model_size(model):
        """è®¡ç®—æ¨¡å‹å¤§å° (MB)"""
        total_size = 0
        for param in model.parameters():
            total_size += param.numel() * param.element_size()
        for buffer in model.buffers():
            total_size += buffer.numel() * buffer.element_size()
        return total_size / 1024 / 1024
    
    # æµ‹é‡æ€§èƒ½
    original_time = measure_inference_time(model, sample_input)
    quantized_time = measure_inference_time(quantized_model, sample_input)
    
    original_size = get_model_size(model)
    quantized_size = get_model_size(quantized_model)
    
    # è¾“å‡ºç»“æœ
    print("\n" + "="*50)
    print("ğŸ“Š é‡åŒ–ç»“æœå¯¹æ¯”")
    print("="*50)
    print(f"ğŸ“ˆ æ¨ç†æ—¶é—´:")
    print(f"  åŸå§‹æ¨¡å‹: {original_time:.2f} ms")
    print(f"  é‡åŒ–æ¨¡å‹: {quantized_time:.2f} ms")
    print(f"  é€Ÿåº¦æå‡: {original_time/quantized_time:.2f}x")
    
    print(f"\nğŸ’¾ æ¨¡å‹å¤§å°:")
    print(f"  åŸå§‹æ¨¡å‹: {original_size:.2f} MB")
    print(f"  é‡åŒ–æ¨¡å‹: {quantized_size:.2f} MB")  
    print(f"  å¤§å°å‹ç¼©: {original_size/quantized_size:.2f}x")
    
    # 7. ä¿å­˜é‡åŒ–æ¨¡å‹
    if output_path:
        print(f"\nğŸ’¾ ä¿å­˜é‡åŒ–æ¨¡å‹åˆ°: {output_path}")
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        
        torch.save({
            'model': quantized_model,
            'model_state_dict': quantized_model.state_dict(),
            'config': cfg.model,
            'performance': {
                'original_time': original_time,
                'quantized_time': quantized_time,
                'original_size': original_size,
                'quantized_size': quantized_size,
                'speed_up': original_time/quantized_time,
                'compression': original_size/quantized_size
            }
        }, output_path)
        print("âœ… æ¨¡å‹ä¿å­˜æˆåŠŸ")
    
    print("\nğŸ‰ é‡åŒ–å®Œæˆ!")
    
    return quantized_model


def main():
    parser = argparse.ArgumentParser(description='PointNeXt ç®€åŒ–é‡åŒ–è„šæœ¬')
    parser.add_argument('--cfg', type=str, required=True, help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--pretrained', type=str, help='é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„')
    parser.add_argument('--output', type=str, help='è¾“å‡ºè·¯å¾„')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥é…ç½®æ–‡ä»¶
    if not os.path.exists(args.cfg):
        print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {args.cfg}")
        return
    
    # è®¾ç½®é»˜è®¤è¾“å‡ºè·¯å¾„
    if not args.output:
        config_name = Path(args.cfg).stem
        args.output = f"quantized_models/{config_name}_quantized.pth"
    
    # å¼€å§‹é‡åŒ–
    try:
        quantized_model = simple_quantize_pointnext(
            args.cfg, 
            args.pretrained, 
            args.output
        )
        
        if quantized_model:
            print(f"\nâœ… é‡åŒ–æˆåŠŸå®Œæˆ!")
            print(f"ğŸ“ é‡åŒ–æ¨¡å‹ä¿å­˜åœ¨: {args.output}")
        else:
            print(f"\nâŒ é‡åŒ–å¤±è´¥!")
            
    except Exception as e:
        print(f"âŒ é‡åŒ–è¿‡ç¨‹å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
