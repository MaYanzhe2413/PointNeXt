#!/usr/bin/env python3
"""
æµ‹è¯•PointNeXt KDTreeé…ç½®æ–‡ä»¶
éªŒè¯æ¨¡å‹èƒ½å¦æ­£ç¡®åŠ è½½å’Œè¿è¡Œ
"""

import sys
import torch
sys.path.append('/workspace/PointNeXt')

from openpoints.utils import EasyConfig
from openpoints.models import build_model_from_cfg

def test_pointnext_kdtree_config(config_path):
    """æµ‹è¯•PointNeXt KDTreeé…ç½®"""
    print(f"\\nğŸ§ª æµ‹è¯•é…ç½®æ–‡ä»¶: {config_path}")
    print("=" * 60)
    
    try:
        # åŠ è½½é…ç½®
        cfg = EasyConfig()
        cfg.load(config_path, recursive=True)
        
        # è®¾ç½®é»˜è®¤å‚æ•°
        if not hasattr(cfg, 'num_classes'):
            cfg.num_classes = 40
        if not hasattr(cfg, 'input_channels'):
            cfg.input_channels = 3
            
        print(f"âœ… é…ç½®æ–‡ä»¶åŠ è½½æˆåŠŸ")
        print(f"   ç¼–ç å™¨: {cfg.model.encoder_args.NAME}")
        print(f"   é‡‡æ ·å™¨: {cfg.model.encoder_args.sampler}")
        print(f"   ç½‘ç»œå®½åº¦: {cfg.model.encoder_args.width}")
        print(f"   ç½‘ç»œæ·±åº¦: {len(cfg.model.encoder_args.blocks)}")
        
        # æ„å»ºæ¨¡å‹
        model = build_model_from_cfg(cfg.model)
        print(f"âœ… æ¨¡å‹æ„å»ºæˆåŠŸ")
        
        # è®¡ç®—å‚æ•°é‡
        total_params = sum(p.numel() for p in model.parameters())
        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
        
        print(f"   æ€»å‚æ•°é‡: {total_params:,}")
        print(f"   å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
        print(f"   å‚æ•°å¤§å°: {total_params * 4 / 1024 / 1024:.2f} MB")
        
        # æµ‹è¯•å‰å‘ä¼ æ’­
        batch_size = 2
        num_points = 1024
        
        # åˆ›å»ºç¬¦åˆPointNeXtæ ¼å¼çš„è¾“å…¥
        pos = torch.randn(batch_size, num_points, 3)
        
        print(f"\\nğŸš€ æµ‹è¯•å‰å‘ä¼ æ’­...")
        print(f"   è¾“å…¥å½¢çŠ¶: {pos.shape}")
        
        # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
        model.eval()
        
        with torch.no_grad():
            # PointNeXtä½¿ç”¨å­—å…¸æ ¼å¼è¾“å…¥
            data = {'pos': pos}
            
            # å‰å‘ä¼ æ’­
            output = model(data)
            
            print(f"âœ… å‰å‘ä¼ æ’­æˆåŠŸ")
            if isinstance(output, dict):
                for key, value in output.items():
                    if isinstance(value, torch.Tensor):
                        print(f"   è¾“å‡º {key}: {value.shape}")
            else:
                print(f"   è¾“å‡ºå½¢çŠ¶: {output.shape}")
                
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """ä¸»å‡½æ•°ï¼šæµ‹è¯•æ‰€æœ‰KDTreeé…ç½®"""
    print("ğŸŒ³ PointNeXt KDTreeé…ç½®æµ‹è¯•")
    print("=" * 60)
    
    configs = [
        "/workspace/PointNeXt/cfgs/modelnet40ply2048/pointnext-s_kdtree.yaml",
        "/workspace/PointNeXt/cfgs/modelnet40ply2048/pointnext-b_kdtree.yaml",
        "/workspace/PointNeXt/cfgs/modelnet40ply2048/pointnext-s_kdtree_adaptive.yaml"
    ]
    
    results = {}
    
    for config_path in configs:
        config_name = config_path.split('/')[-1].replace('.yaml', '')
        results[config_name] = test_pointnext_kdtree_config(config_path)
        print()
    
    # æ±‡æ€»ç»“æœ
    print("\\nğŸ“Š æµ‹è¯•ç»“æœæ±‡æ€»:")
    print("=" * 60)
    for config_name, success in results.items():
        status = "âœ… æˆåŠŸ" if success else "âŒ å¤±è´¥"
        print(f"   {config_name:<30} {status}")
    
    success_count = sum(results.values())
    total_count = len(results)
    print(f"\\næ€»ä½“ç»“æœ: {success_count}/{total_count} é…ç½®æµ‹è¯•é€šè¿‡")
    
    if success_count == total_count:
        print("ğŸ‰ æ‰€æœ‰KDTreeé…ç½®æµ‹è¯•é€šè¿‡ï¼")
        print("\\nğŸš€ å¯ä»¥å¼€å§‹è®­ç»ƒ:")
        print("   ./run_training.sh classification pointnext-s_kdtree modelnet40")
        print("   ./run_training.sh classification pointnext-b_kdtree modelnet40")
    else:
        print("âš ï¸  éƒ¨åˆ†é…ç½®éœ€è¦ä¿®å¤")

if __name__ == "__main__":
    main()