#!/usr/bin/env python3
"""
Dockerç¯å¢ƒä¸“ç”¨çš„KITTIç‚¹äº‘é…å‡†åˆ†æè„šæœ¬
å®Œå…¨é¿å…GUIï¼Œåªç”Ÿæˆå›¾ç‰‡å’Œæ–‡æœ¬è¾“å‡º
"""
import os
import sys
import glob
import struct
import math
import time

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append('/workspace/PointNeXt')

# å¼ºåˆ¶matplotlibä½¿ç”¨éäº¤äº’å¼åç«¯
import matplotlib
matplotlib.use('Agg')  # å¿…é¡»åœ¨import pyplotä¹‹å‰è®¾ç½®

# å°è¯•å¯¼å…¥Open3Dï¼ˆç”¨äºé…å‡†è®¡ç®—ï¼Œä¸ç”¨äºå¯è§†åŒ–ï¼‰
try:
    import open3d as o3d
    HAS_OPEN3D = True
    print("âœ… Open3Då·²åŠ è½½ï¼ˆä»…ç”¨äºè®¡ç®—ï¼Œä¸ä½¿ç”¨GUIï¼‰")
except ImportError:
    HAS_OPEN3D = False
    print("âš ï¸  Open3Dæœªå®‰è£…ï¼Œå°†è·³è¿‡é…å‡†åŠŸèƒ½")

# å¯¼å…¥matplotlibï¼ˆéGUIæ¨¡å¼ï¼‰
try:
    import matplotlib
    matplotlib.use('Agg')  # å¿…é¡»åœ¨import pyplotä¹‹å‰è®¾ç½®
    import matplotlib.pyplot as plt
    from mpl_toolkits.mplot3d import Axes3D
    
    # è®¾ç½®å­—ä½“ä»¥é¿å…ä¸­æ–‡å­—ç¬¦é—®é¢˜
    plt.rcParams['font.family'] = 'DejaVu Sans'
    plt.rcParams['axes.unicode_minus'] = False
    
    HAS_MATPLOTLIB = True
    print("âœ… matplotlibå·²åŠ è½½ï¼ˆéGUIæ¨¡å¼ï¼Œè‹±æ–‡å­—ä½“ï¼‰")
except ImportError:
    HAS_MATPLOTLIB = False
    print("âš ï¸  matplotlibæœªå®‰è£…ï¼Œå°†è·³è¿‡å›¾å½¢å¯è§†åŒ–")

def load_kitti_bin_simple(file_path):
    """ç®€å•ç‰ˆæœ¬çš„KITTI .binæ–‡ä»¶åŠ è½½å™¨"""
    try:
        with open(file_path, 'rb') as f:
            data = f.read()
        
        num_points = len(data) // 16
        points = []
        
        for i in range(num_points):
            offset = i * 16
            x, y, z, intensity = struct.unpack('<ffff', data[offset:offset+16])
            points.append((x, y, z, intensity))
        
        return points
    except Exception as e:
        print(f"åŠ è½½æ–‡ä»¶å¤±è´¥: {e}")
        return []

def load_kitti_to_open3d(file_path, max_points=None):
    """åŠ è½½KITTIæ•°æ®å¹¶è½¬æ¢ä¸ºOpen3Dç‚¹äº‘æ ¼å¼"""
    if not HAS_OPEN3D:
        return None
    
    points = load_kitti_bin_simple(file_path)
    if not points:
        return None
    
    # ä¸‹é‡‡æ ·
    if max_points and len(points) > max_points:
        step = len(points) // max_points
        points = points[::step]
    
    coords = [[p[0], p[1], p[2]] for p in points]
    
    pcd = o3d.geometry.PointCloud()
    pcd.points = o3d.utility.Vector3dVector(coords)
    
    return pcd

def register_point_clouds_open3d(source_pcd, target_pcd, method='icp'):
    """ä½¿ç”¨Open3Dè¿›è¡Œç‚¹äº‘é…å‡†ï¼ˆæ— GUIï¼‰"""
    if not HAS_OPEN3D:
        return None, None, {}
    
    print(f"ğŸ”„ Executing {method} registration...")
    
    # ä¼°è®¡æ³•å‘é‡
    source_pcd.estimate_normals()
    target_pcd.estimate_normals()
    
    if method == 'icp':
        threshold = 2.0
        reg_result = o3d.pipelines.registration.registration_icp(
            source_pcd, target_pcd, threshold,
            estimation_method=o3d.pipelines.registration.TransformationEstimationPointToPoint(),
            criteria=o3d.pipelines.registration.ICPConvergenceCriteria(max_iteration=50)
        )
    else:  # feature-based
        voxel_size = 1.0
        
        source_down = source_pcd.voxel_down_sample(voxel_size)
        target_down = target_pcd.voxel_down_sample(voxel_size)
        
        radius_normal = voxel_size * 2
        source_down.estimate_normals(o3d.geometry.KDTreeSearchParamHybrid(radius=radius_normal, max_nn=30))
        target_down.estimate_normals(o3d.geometry.KDTreeSearchParamHybrid(radius=radius_normal, max_nn=30))
        
        radius_feature = voxel_size * 5
        source_fpfh = o3d.pipelines.registration.compute_fpfh_feature(
            source_down, o3d.geometry.KDTreeSearchParamHybrid(radius=radius_feature, max_nn=100))
        target_fpfh = o3d.pipelines.registration.compute_fpfh_feature(
            target_down, o3d.geometry.KDTreeSearchParamHybrid(radius=radius_feature, max_nn=100))
        
        distance_threshold = 1.5
        reg_result = o3d.pipelines.registration.registration_ransac_based_on_feature_matching(
            source_down, target_down, source_fpfh, target_fpfh, True, distance_threshold,
            o3d.pipelines.registration.TransformationEstimationPointToPoint(False), 3,
            [o3d.pipelines.registration.CorrespondenceCheckerBasedOnEdgeLength(0.9),
             o3d.pipelines.registration.CorrespondenceCheckerBasedOnDistance(distance_threshold)],
            o3d.pipelines.registration.RANSACConvergenceCriteria(100000, 0.999))
        
        # ç²¾ç»†ICP
        reg_result = o3d.pipelines.registration.registration_icp(
            source_pcd, target_pcd, distance_threshold, reg_result.transformation,
            o3d.pipelines.registration.TransformationEstimationPointToPoint())
    
    source_registered = source_pcd.transform(reg_result.transformation)
    
    reg_info = {
        'method': method,
        'fitness': reg_result.fitness,
        'inlier_rmse': reg_result.inlier_rmse,
        'transformation': reg_result.transformation,
        'correspondence_set': len(reg_result.correspondence_set)
    }
    
    print(f"âœ… Registration completed - Fitness: {reg_info['fitness']:.4f}, RMSE: {reg_info['inlier_rmse']:.4f}")
    
    return source_registered, reg_result.transformation, reg_info

def create_registration_comparison_plot(points_A_original, points_A_registered, points_B, reg_info, output_dir):
    """åˆ›å»ºé…å‡†å‰åå¯¹æ¯”å›¾ï¼ˆDockerå‹å¥½ç‰ˆï¼‰"""
    if not HAS_MATPLOTLIB:
        print("âŒ matplotlibä¸å¯ç”¨ï¼Œè·³è¿‡å›¾å½¢å¯¹æ¯”")
        return
    
    print("ğŸ“Š Generating registration comparison plot...")
    
    # æå–åæ ‡ï¼ˆä¸‹é‡‡æ ·ä»¥æé«˜æ€§èƒ½ï¼‰
    def downsample_points(points, max_points=5000):
        if len(points) <= max_points:
            return points
        step = len(points) // max_points
        return points[::step]
    
    points_A_orig_down = downsample_points(points_A_original)
    points_A_reg_down = downsample_points(points_A_registered)
    points_B_down = downsample_points(points_B)
    
    x_orig = [p[0] for p in points_A_orig_down]
    y_orig = [p[1] for p in points_A_orig_down]
    z_orig = [p[2] for p in points_A_orig_down]
    
    x_reg = [p[0] for p in points_A_reg_down]
    y_reg = [p[1] for p in points_A_reg_down]
    z_reg = [p[2] for p in points_A_reg_down]
    
    x_B = [p[0] for p in points_B_down]
    y_B = [p[1] for p in points_B_down]
    z_B = [p[2] for p in points_B_down]
    
    # åˆ›å»ºå›¾å½¢
    fig = plt.figure(figsize=(20, 12))
    
    # 1. é…å‡†å‰3Dè§†å›¾
    ax1 = fig.add_subplot(2, 3, 1, projection='3d')
    ax1.scatter(x_orig, y_orig, z_orig, c='red', s=0.5, alpha=0.6, label='Frame A (Original)')
    ax1.scatter(x_B, y_B, z_B, c='blue', s=0.5, alpha=0.6, label='Frame B (Target)')
    ax1.set_title('Before Registration - 3D View', fontsize=14)
    ax1.set_xlabel('X (m)')
    ax1.set_ylabel('Y (m)')
    ax1.set_zlabel('Z (m)')
    ax1.legend()
    
    # 2. é…å‡†å3Dè§†å›¾
    ax2 = fig.add_subplot(2, 3, 2, projection='3d')
    ax2.scatter(x_reg, y_reg, z_reg, c='green', s=0.5, alpha=0.6, label='Frame A (Registered)')
    ax2.scatter(x_B, y_B, z_B, c='blue', s=0.5, alpha=0.6, label='Frame B (Target)')
    ax2.set_title('After Registration - 3D View', fontsize=14)
    ax2.set_xlabel('X (m)')
    ax2.set_ylabel('Y (m)')
    ax2.set_zlabel('Z (m)')
    ax2.legend()
    
    # 3. é…å‡†å‰ä¿¯è§†å›¾
    ax3 = fig.add_subplot(2, 3, 3)
    ax3.scatter(x_orig, y_orig, c='red', s=0.5, alpha=0.6, label='Frame A (Original)')
    ax3.scatter(x_B, y_B, c='blue', s=0.5, alpha=0.6, label='Frame B (Target)')
    ax3.set_title('Before Registration - Top View', fontsize=14)
    ax3.set_xlabel('X (m)')
    ax3.set_ylabel('Y (m)')
    ax3.legend()
    ax3.grid(True, alpha=0.3)
    ax3.axis('equal')
    
    # 4. é…å‡†åä¿¯è§†å›¾
    ax4 = fig.add_subplot(2, 3, 4)
    ax4.scatter(x_reg, y_reg, c='green', s=0.5, alpha=0.6, label='Frame A (Registered)')
    ax4.scatter(x_B, y_B, c='blue', s=0.5, alpha=0.6, label='Frame B (Target)')
    ax4.set_title('After Registration - Top View', fontsize=14)
    ax4.set_xlabel('X (m)')
    ax4.set_ylabel('Y (m)')
    ax4.legend()
    ax4.grid(True, alpha=0.3)
    ax4.axis('equal')
    
    # 5. å˜æ¢çŸ©é˜µå¯è§†åŒ–
    ax5 = fig.add_subplot(2, 3, 5)
    if 'transformation' in reg_info:
        T = reg_info['transformation']
        im = ax5.imshow(T, cmap='coolwarm', aspect='equal')
        ax5.set_title('Transformation Matrix', fontsize=14)
        for i in range(4):
            for j in range(4):
                ax5.text(j, i, f'{T[i,j]:.3f}', ha='center', va='center', fontsize=8)
        plt.colorbar(im, ax=ax5)
    
    # 6. é…å‡†ç»Ÿè®¡ä¿¡æ¯
    ax6 = fig.add_subplot(2, 3, 6)
    ax6.axis('off')
    stats_text = f"""Registration Statistics:

Method: {reg_info.get('method', 'N/A')}
Fitness: {reg_info.get('fitness', 0):.4f}
RMSE: {reg_info.get('inlier_rmse', 0):.4f}
Correspondences: {reg_info.get('correspondence_set', 0)}

Frame A Original Points: {len(points_A_original)}
Frame A Registered Points: {len(points_A_registered)}
Frame B Points: {len(points_B)}

Displayed Points (downsampled):
- Frame A Original: {len(points_A_orig_down)}
- Frame A Registered: {len(points_A_reg_down)}
- Frame B: {len(points_B_down)}
"""
    ax6.text(0.1, 0.9, stats_text, transform=ax6.transAxes, fontsize=11,
             verticalalignment='top', bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))
    
    plt.tight_layout()
    
    # ä¿å­˜å›¾ç‰‡
    output_path = os.path.join(output_dir, 'kitti_registration_comparison.png')
    plt.savefig(output_path, dpi=150, bbox_inches='tight')
    print(f"ğŸ“Š Registration comparison plot saved to: {output_path}")
    
    plt.close()
    return output_path

def analyze_registration_differences(points_A_original, points_A_registered, points_B):
    """åˆ†æé…å‡†å‰åçš„æ•°æ®å·®å¼‚"""
    print(f"=== Registration Effect Analysis ===")
    
    def compute_centroid(points):
        x_mean = sum(p[0] for p in points) / len(points)
        y_mean = sum(p[1] for p in points) / len(points)
        z_mean = sum(p[2] for p in points) / len(points)
        return (x_mean, y_mean, z_mean)
    
    centroid_A_orig = compute_centroid(points_A_original)
    centroid_A_reg = compute_centroid(points_A_registered)
    centroid_B = compute_centroid(points_B)
    
    print(f"Centroid Coordinates:")
    print(f"  Frame A (Original): ({centroid_A_orig[0]:.2f}, {centroid_A_orig[1]:.2f}, {centroid_A_orig[2]:.2f})")
    print(f"  Frame A (Registered): ({centroid_A_reg[0]:.2f}, {centroid_A_reg[1]:.2f}, {centroid_A_reg[2]:.2f})")
    print(f"  Frame B (Target): ({centroid_B[0]:.2f}, {centroid_B[1]:.2f}, {centroid_B[2]:.2f})")
    
    def distance_3d(p1, p2):
        return math.sqrt((p1[0]-p2[0])**2 + (p1[1]-p2[1])**2 + (p1[2]-p2[2])**2)
    
    dist_before = distance_3d(centroid_A_orig, centroid_B)
    dist_after = distance_3d(centroid_A_reg, centroid_B)
    improvement = dist_before - dist_after
    transform_distance = distance_3d(centroid_A_orig, centroid_A_reg)
    
    print(f"\nCentroid Distance:")
    print(f"  Before Registration: {dist_before:.2f}m")
    print(f"  After Registration: {dist_after:.2f}m")
    print(f"  Improvement: {improvement:.2f}m ({improvement/dist_before*100:.1f}%)")
    print(f"  Frame A Transform Distance: {transform_distance:.2f}m")
    
    return {
        'centroid_A_original': centroid_A_orig,
        'centroid_A_registered': centroid_A_reg,
        'centroid_B': centroid_B,
        'distance_before': dist_before,
        'distance_after': dist_after,
        'improvement': improvement,
        'transform_distance': transform_distance
    }

def test_icp_convergence(source_pcd, target_pcd, max_iterations_list=None, threshold=2.0):
    """æµ‹è¯•ä¸åŒè¿­ä»£æ¬¡æ•°ä¸‹çš„ICPæ”¶æ•›æ•ˆæœ"""
    if max_iterations_list is None:
        max_iterations_list = list(range(3, 21))  # é»˜è®¤3-20æ¬¡ï¼Œæ­¥é•¿1
    
    print(f"\nğŸ”¬ Testing Point-to-Point ICP Convergence...")
    print(f"Testing iterations: {max_iterations_list}")
    print(f"Total tests to run: {len(max_iterations_list)}")
    
    convergence_results = {}
    
    for max_iter in max_iterations_list:
        print(f"\n--- Testing {max_iter} iterations ---")
        
        # åˆ›å»ºç‚¹äº‘å‰¯æœ¬
        source_copy = source_pcd.__copy__()
        target_copy = target_pcd.__copy__()
        
        # ä¼°è®¡æ³•å‘é‡
        source_copy.estimate_normals()
        target_copy.estimate_normals()
        
        # è®°å½•å¼€å§‹æ—¶é—´
        start_time = time.time()
        
        # æ‰§è¡ŒICP
        reg_result = o3d.pipelines.registration.registration_icp(
            source_copy, target_copy, threshold,
            estimation_method=o3d.pipelines.registration.TransformationEstimationPointToPoint(),
            criteria=o3d.pipelines.registration.ICPConvergenceCriteria(max_iteration=max_iter)
        )
        
        # è®°å½•æ‰§è¡Œæ—¶é—´
        execution_time = time.time() - start_time
        
        # ä¿å­˜ç»“æœ
        convergence_results[max_iter] = {
            'fitness': reg_result.fitness,
            'rmse': reg_result.inlier_rmse,
            'correspondences': len(reg_result.correspondence_set),
            'execution_time': execution_time
        }
        
        print(f"   Fitness: {reg_result.fitness:.6f}")
        print(f"   RMSE: {reg_result.inlier_rmse:.6f}")
        print(f"   Correspondences: {len(reg_result.correspondence_set)}")
        print(f"   Time: {execution_time:.3f}s")
    
    return convergence_results

def analyze_convergence_efficiency(convergence_results):
    """åˆ†ææ”¶æ•›æ•ˆç‡ - é’ˆå¯¹ç»†ç²’åº¦è¿­ä»£ä¼˜åŒ–"""
    print(f"\nğŸ“Š Fine-grained Convergence Efficiency Analysis:")
    print(f"{'Iter':<6} {'Fitness':<12} {'RMSE':<12} {'Time(s)':<8} {'Efficiency':<10} {'Quality':<8} {'Change':<8}")
    print("-" * 80)
    
    best_efficiency = 0
    best_efficiency_iter = 0
    best_quality = 0
    best_quality_iter = 0
    convergence_detected_at = None
    
    sorted_iters = sorted(convergence_results.keys())
    prev_fitness = None
    prev_rmse = None
    
    for i, max_iter in enumerate(sorted_iters):
        result = convergence_results[max_iter]
        
        # è®¡ç®—æ•ˆç‡æŒ‡æ ‡ï¼šé€‚åº”åº¦/æ—¶é—´
        efficiency = result['fitness'] / result['execution_time']
        
        # è®¡ç®—è´¨é‡æŒ‡æ ‡ï¼šé€‚åº”åº¦ - RMSEå½’ä¸€åŒ–
        quality = result['fitness'] - (result['rmse'] / 10.0)  # ç®€å•å½’ä¸€åŒ–
        
        # è®¡ç®—ç›¸å¯¹ä¸Šæ¬¡çš„å˜åŒ–
        if prev_fitness is not None:
            fitness_change = abs(result['fitness'] - prev_fitness)
            rmse_change = abs(result['rmse'] - prev_rmse)
            change_magnitude = fitness_change + rmse_change
        else:
            change_magnitude = float('inf')
        
        print(f"{max_iter:<6} {result['fitness']:<12.6f} {result['rmse']:<12.6f} "
              f"{result['execution_time']:<8.3f} {efficiency:<10.3f} {quality:<8.3f} {change_magnitude:<8.6f}")
        
        # æ£€æµ‹æ”¶æ•›ï¼ˆå˜åŒ–å¾ˆå°ï¼‰
        if change_magnitude < 1e-5 and convergence_detected_at is None and i > 2:
            convergence_detected_at = max_iter
            print(f"    â­ Potential convergence detected!")
        
        if efficiency > best_efficiency:
            best_efficiency = efficiency
            best_efficiency_iter = max_iter
        
        if quality > best_quality:
            best_quality = quality
            best_quality_iter = max_iter
        
        prev_fitness = result['fitness']
        prev_rmse = result['rmse']
    
    print(f"\nğŸ† Best Efficiency: {best_efficiency:.3f} at {best_efficiency_iter} iterations")
    print(f"ğŸ¯ Best Quality: {best_quality:.3f} at {best_quality_iter} iterations")
    
    if convergence_detected_at:
        print(f"âœ… Early convergence detected at: {convergence_detected_at} iterations")
        print(f"ğŸ’¡ Recommended minimum iterations: {convergence_detected_at}")
        print(f"ğŸ”§ Optimal iterations (with safety margin): {convergence_detected_at + 2}")
    else:
        print(f"âš ï¸  No clear convergence point detected in tested range")
        print(f"ğŸ’¡ Consider testing with higher iteration counts or the algorithm may need more iterations")
    
    # åˆ†ææ”¶æ•›æ›²çº¿çš„æ–œç‡å˜åŒ–
    fitness_values = [convergence_results[k]['fitness'] for k in sorted_iters]
    rmse_values = [convergence_results[k]['rmse'] for k in sorted_iters]
    
    # è®¡ç®—è¿ç»­ä¸‰ç‚¹çš„å¹³å‡å˜åŒ–ç‡
    if len(fitness_values) >= 5:
        recent_fitness_changes = []
        recent_rmse_changes = []
        
        for i in range(len(fitness_values) - 3):
            fitness_slope = abs(fitness_values[i+3] - fitness_values[i]) / 3
            rmse_slope = abs(rmse_values[i+3] - rmse_values[i]) / 3
            recent_fitness_changes.append(fitness_slope)
            recent_rmse_changes.append(rmse_slope)
        
        avg_recent_fitness_change = sum(recent_fitness_changes[-3:]) / 3 if len(recent_fitness_changes) >= 3 else 0
        avg_recent_rmse_change = sum(recent_rmse_changes[-3:]) / 3 if len(recent_rmse_changes) >= 3 else 0
        
        if avg_recent_fitness_change < 1e-6 and avg_recent_rmse_change < 1e-6:
            print(f"ğŸ“ˆ Convergence curve analysis: STABLE (very low change rate)")
        elif avg_recent_fitness_change < 1e-4 and avg_recent_rmse_change < 1e-4:
            print(f"ğŸ“ˆ Convergence curve analysis: CONVERGING (decreasing change rate)")
        else:
            print(f"ï¿½ Convergence curve analysis: STILL_IMPROVING (significant changes)")
    
    return best_efficiency_iter, best_quality_iter

def create_convergence_plot(convergence_results, output_dir):
    """åˆ›å»ºæ”¶æ•›åˆ†æå›¾è¡¨"""
    if not HAS_MATPLOTLIB:
        print("âŒ matplotlib not available for plotting")
        return None
    
    print("ğŸ“ˆ Creating convergence analysis plot...")
    
    iterations = sorted(convergence_results.keys())
    fitness_values = [convergence_results[k]['fitness'] for k in iterations]
    rmse_values = [convergence_results[k]['rmse'] for k in iterations]
    time_values = [convergence_results[k]['execution_time'] for k in iterations]
    efficiency_values = [convergence_results[k]['fitness'] / convergence_results[k]['execution_time'] for k in iterations]
    
    # åˆ›å»º2x2å­å›¾
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    fig.suptitle('ICP Convergence Analysis', fontsize=16, fontweight='bold')
    
    # 1. Fitness vs Iterations
    ax1 = axes[0, 0]
    ax1.plot(iterations, fitness_values, 'b-o', linewidth=2, markersize=6)
    ax1.set_xlabel('Max Iterations')
    ax1.set_ylabel('Fitness')
    ax1.set_title('Fitness vs Max Iterations')
    ax1.grid(True, alpha=0.3)
    
    # æ ‡æ³¨æ•°å€¼
    for i, (x, y) in enumerate(zip(iterations, fitness_values)):
        if i % 2 == 0:  # åªæ ‡æ³¨éƒ¨åˆ†ç‚¹é¿å…é‡å 
            ax1.annotate(f'{y:.4f}', (x, y), textcoords="offset points", 
                        xytext=(0,10), ha='center', fontsize=8)
    
    # 2. RMSE vs Iterations
    ax2 = axes[0, 1]
    ax2.plot(iterations, rmse_values, 'r-s', linewidth=2, markersize=6)
    ax2.set_xlabel('Max Iterations')
    ax2.set_ylabel('RMSE')
    ax2.set_title('RMSE vs Max Iterations')
    ax2.grid(True, alpha=0.3)
    
    # 3. Execution Time vs Iterations
    ax3 = axes[1, 0]
    ax3.plot(iterations, time_values, 'g-^', linewidth=2, markersize=6)
    ax3.set_xlabel('Max Iterations')
    ax3.set_ylabel('Execution Time (s)')
    ax3.set_title('Execution Time vs Max Iterations')
    ax3.grid(True, alpha=0.3)
    
    # æ·»åŠ çº¿æ€§æ‹Ÿåˆçº¿
    import numpy as np
    z = np.polyfit(iterations, time_values, 1)
    p = np.poly1d(z)
    ax3.plot(iterations, p(iterations), "g--", alpha=0.8, 
             label=f'Linear fit: y={z[0]:.4f}x+{z[1]:.4f}')
    ax3.legend()
    
    # 4. Efficiency Analysis
    ax4 = axes[1, 1]
    bars = ax4.bar(iterations, efficiency_values, color='orange', alpha=0.7)
    ax4.set_xlabel('Max Iterations')
    ax4.set_ylabel('Efficiency (Fitness/Time)')
    ax4.set_title('Registration Efficiency')
    ax4.grid(True, alpha=0.3)
    
    # æ ‡æ³¨æœ€é«˜æ•ˆç‡
    max_eff_idx = efficiency_values.index(max(efficiency_values))
    max_eff_iter = iterations[max_eff_idx]
    ax4.annotate(f'Best: {max(efficiency_values):.2f}', 
                xy=(max_eff_iter, max(efficiency_values)),
                xytext=(max_eff_iter, max(efficiency_values) + max(efficiency_values)*0.1),
                arrowprops=dict(arrowstyle='->', color='red'),
                ha='center', fontweight='bold', color='red')
    
    plt.tight_layout()
    
    # ä¿å­˜å›¾ç‰‡
    output_path = os.path.join(output_dir, 'icp_convergence_analysis.png')
    plt.savefig(output_path, dpi=150, bbox_inches='tight')
    print(f"ğŸ“Š Convergence analysis saved to: {output_path}")
    
    plt.close()
    return output_path

def main():
    """ä¸»å‡½æ•° - Dockerç¯å¢ƒä¸“ç”¨"""
    print("=== Docker Environment KITTI Point Cloud Registration Analysis ===")
    print("ğŸ³ Docker-friendly mode - No GUI visualization")
    
    # æ•°æ®è·¯å¾„
    kitti_data_dir = "/workspace/data/kitti"
    
    # è¾“å‡ºç›®å½•
    output_dir = "/workspace/PointNeXt/kitti_analysis"
    os.makedirs(output_dir, exist_ok=True)
    
    # éªŒè¯è·¯å¾„
    velodyne_dir = os.path.join(kitti_data_dir, "sequences", "00", "velodyne")
    if not os.path.exists(velodyne_dir):
        print(f"âŒ velodyne directory not found: {velodyne_dir}")
        return
    
    velodyne_files = sorted(glob.glob(os.path.join(velodyne_dir, "*.bin")))
    if len(velodyne_files) < 2:
        print("âŒ Need at least 2 files for registration comparison")
        return
    
    print(f"âœ… Found {len(velodyne_files)} files")
    
    if not HAS_OPEN3D:
        print("âŒ Open3D not available, cannot perform registration analysis")
        return
    
    # é€‰æ‹©è¦é…å‡†çš„å¸§
    frame_A_file = velodyne_files[0]
    frame_B_file = velodyne_files[1]
    
    print(f"\nRegistration frames:")
    print(f"  Frame A: {os.path.basename(frame_A_file)}")
    print(f"  Frame B: {os.path.basename(frame_B_file)}")
    
    # åŠ è½½ç‚¹äº‘æ•°æ®
    print(f"\n--- Loading point cloud data ---")
    pcd_A = load_kitti_to_open3d(frame_A_file, max_points=10000)  # å‡å°‘ç‚¹æ•°æé«˜æ€§èƒ½
    pcd_B = load_kitti_to_open3d(frame_B_file, max_points=10000)
    
    if pcd_A is None or pcd_B is None:
        print("âŒ Point cloud loading failed")
        return
    
    print(f"Frame A: {len(pcd_A.points)} points")
    print(f"Frame B: {len(pcd_B.points)} points")
    
    # ä¿å­˜åŸå§‹Aç‚¹äº‘çš„å‰¯æœ¬
    pcd_A_original = pcd_A.__copy__()
    
    # æ‰§è¡ŒICPé…å‡†
    print(f"\n--- Executing ICP Registration ---")
    pcd_A_registered, transformation, reg_info = register_point_clouds_open3d(
        pcd_A, pcd_B, method='icp'
    )
    
    if pcd_A_registered is not None:
        # è½¬æ¢ä¸ºåŸå§‹æ•°æ®æ ¼å¼è¿›è¡Œåˆ†æ
        points_A_original = load_kitti_bin_simple(frame_A_file)
        points_A_registered = [[p[0], p[1], p[2], 0] for p in pcd_A_registered.points]
        points_B = load_kitti_bin_simple(frame_B_file)
        
        # æ•°å€¼åˆ†æ
        analysis_result = analyze_registration_differences(
            points_A_original, points_A_registered, points_B
        )
        
        # åˆ›å»ºmatplotlibå¯¹æ¯”å›¾
        plot_path = create_registration_comparison_plot(
            points_A_original, points_A_registered, points_B, reg_info, output_dir
        )
        
        # é…å‡†ç»Ÿè®¡
        print(f"\n--- Registration Results ---")
        print(f"Registration method: {reg_info['method']}")
        print(f"Fitness: {reg_info['fitness']:.4f}")
        print(f"RMSE: {reg_info['inlier_rmse']:.4f}")
        print(f"Correspondences: {reg_info['correspondence_set']}")
        
        # æ”¶æ•›æ€§æµ‹è¯• - ç»†ç²’åº¦æµ‹è¯•3-20æ¬¡è¿­ä»£
        print(f"\nğŸ”¬ Starting Fine-grained ICP Convergence Test...")
        print(f"ğŸ¯ Testing iterations 3-20 with step size 1")
        convergence_results = test_icp_convergence(
            pcd_A_original, pcd_B, 
            max_iterations_list=list(range(3, 21)),  # 3åˆ°20ï¼Œæ­¥é•¿ä¸º1
            threshold=2.0
        )
        best_efficiency_iter, best_quality_iter = analyze_convergence_efficiency(convergence_results)
        convergence_plot_path = create_convergence_plot(convergence_results, output_dir)
        
        print(f"\nğŸ‰ Docker environment registration analysis completed!")
        print(f"\n" + "="*60)
        print("ï¿½ FINAL ANALYSIS SUMMARY")
        print("="*60)
        print(f"ï¿½ğŸ“Š Data path: {kitti_data_dir}")
        print(f"ï¿½ Results saved to: {output_dir}")
        print(f"ğŸ”„ Registration Fitness: {reg_info['fitness']:.6f}")
        print(f"ğŸ“ Registration RMSE: {reg_info['inlier_rmse']:.6f}")
        print(f"âš¡ Best Efficiency at: {best_efficiency_iter} iterations")
        print(f"ğŸ¯ Best Quality at: {best_quality_iter} iterations")
        if plot_path:
            print(f"ğŸ–¼ï¸  Registration visualization: {plot_path}")
        if convergence_plot_path:
            print(f"ğŸ“ˆ Convergence analysis: {convergence_plot_path}")
        print(f"ğŸ’¡ Please download the PNG files to view visualization results")
        print("="*60)
    else:
        print("âŒ Registration failed")

if __name__ == "__main__":
    main()
