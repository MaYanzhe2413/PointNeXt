#!/usr/bin/env python3
"""
ä½¿ç”¨KITTIæ•°æ®é›†æµ‹è¯• BlockWiseTransfer çš„ forward å‡½æ•°
"""
import torch
import numpy as np
import sys
import os
import glob
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D

# å°è¯•å¯¼å…¥é…å‡†ç›¸å…³åº“
try:
    import open3d as o3d
    HAS_OPEN3D = True
    print("âœ… Open3Då·²åŠ è½½")
except ImportError:
    HAS_OPEN3D = False
    print("âš ï¸  Open3Dæœªå®‰è£…ï¼Œå°†è·³è¿‡é«˜çº§é…å‡†åŠŸèƒ½")
    print("ğŸ’¡ å®‰è£…å»ºè®®: pip install open3d")

try:
    import pcl
    HAS_PCL = True
except ImportError:
    HAS_PCL = False

# å¯¼å…¥scipyç”¨äºç®€å•é…å‡†
try:
    from scipy.spatial.distance import cdist
    from scipy.optimize import minimize
    HAS_SCIPY = True
    print("âœ… SciPyå·²åŠ è½½ï¼Œå¯ä½¿ç”¨ç®€å•é…å‡†")
except ImportError:
    HAS_SCIPY = False
    print("âš ï¸  SciPyæœªå®‰è£…ï¼Œé…å‡†åŠŸèƒ½å—é™")
    print("ğŸ’¡ å®‰è£…å»ºè®®: pip install scipy")

# æ·»åŠ é¡¹ç›®è·¯å¾„åˆ° sys.path
sys.path.append('/workspace/PointNeXt')

from openpoints.models.custom.blockwise import BlockWiseTransfer

def load_kitti_bin(file_path):
    """
    åŠ è½½KITTI .binç‚¹äº‘æ–‡ä»¶
    KITTIæ ¼å¼: [x, y, z, intensity] (N, 4)
    """
    points = np.fromfile(file_path, dtype=np.float32).reshape(-1, 4)
    return points

def load_kitti_txt(file_path):
    """
    åŠ è½½KITTI .txtç‚¹äº‘æ–‡ä»¶ (å¦‚æœæœ‰çš„è¯)
    """
    points = np.loadtxt(file_path, dtype=np.float32)
    return points

def preprocess_kitti_data(points, max_points=50000, coord_range=None):
    """
    é¢„å¤„ç†KITTIç‚¹äº‘æ•°æ®
    
    Args:
        points: (N, 4) numpy array [x, y, z, intensity]
        max_points: æœ€å¤§ç‚¹æ•°é™åˆ¶
        coord_range: åæ ‡èŒƒå›´é™åˆ¶ [(x_min, x_max), (y_min, y_max), (z_min, z_max)]
    
    Returns:
        processed_points: (M, 4) torch tensor [x, y, z, intensity]
    """
    # ç§»é™¤æ— æ•ˆç‚¹
    valid_mask = ~np.isnan(points).any(axis=1) & ~np.isinf(points).any(axis=1)
    points = points[valid_mask]
    
    # åæ ‡èŒƒå›´è¿‡æ»¤ (å»é™¤è¿‡è¿œçš„ç‚¹)
    if coord_range is None:
        # å…¨å±€KITTIåæ ‡èŒƒå›´ - ä¸é™åˆ¶èŒƒå›´ï¼Œä¿ç•™æ‰€æœ‰æœ‰æ•ˆç‚¹
        coord_range = [(-1000, 1000), (-1000, 1000), (-100, 100)]
    
    x_min, x_max = coord_range[0]
    y_min, y_max = coord_range[1]
    z_min, z_max = coord_range[2]
    
    range_mask = (
        (points[:, 0] >= x_min) & (points[:, 0] <= x_max) &
        (points[:, 1] >= y_min) & (points[:, 1] <= y_max) &
        (points[:, 2] >= z_min) & (points[:, 2] <= z_max)
    )
    points = points[range_mask]
    
    # éšæœºä¸‹é‡‡æ ·åˆ°æŒ‡å®šç‚¹æ•°
    if len(points) > max_points:
        indices = np.random.choice(len(points), max_points, replace=False)
        points = points[indices]
    
    # è½¬æ¢ä¸ºtorch tensor
    points_tensor = torch.from_numpy(points).float()
    
    return points_tensor

def create_features_from_kitti(points, feature_dim=64):
    """
    ä»KITTIç‚¹äº‘åˆ›å»ºç‰¹å¾
    
    Args:
        points: (N, 4) torch tensor [x, y, z, intensity]
        feature_dim: ç‰¹å¾ç»´åº¦
    
    Returns:
        points_with_features: (N, 3+feature_dim) torch tensor
    """
    coords = points[:, :3]  # [x, y, z]
    intensity = points[:, 3:4]  # intensity
    
    # è®¡ç®—åŸºç¡€å‡ ä½•ç‰¹å¾
    # 1. è·ç¦»ç‰¹å¾
    distance = torch.norm(coords, dim=1, keepdim=True)
    
    # 2. é«˜åº¦ç‰¹å¾
    height = coords[:, 2:3]
    
    # 3. å¼ºåº¦ç‰¹å¾
    intensity_norm = (intensity - intensity.mean()) / (intensity.std() + 1e-8)
    
    # 4. å±€éƒ¨å¯†åº¦ç‰¹å¾ (ç®€åŒ–ç‰ˆ)
    # è¿™é‡Œä½¿ç”¨éšæœºç‰¹å¾ä»£æ›¿å¤æ‚çš„å¯†åº¦è®¡ç®—
    remaining_features = torch.randn(len(points), feature_dim - 3)
    
    # ç»„åˆæ‰€æœ‰ç‰¹å¾
    features = torch.cat([
        distance,           # 1ç»´
        height,            # 1ç»´  
        intensity_norm,    # 1ç»´
        remaining_features # feature_dim-3 ç»´
    ], dim=1)
    
    # åˆå¹¶åæ ‡å’Œç‰¹å¾
    points_with_features = torch.cat([coords, features], dim=1)
    
    return points_with_features

def test_with_kitti_data(data_dir, sequence_id="00", frame_ids=[0, 1], device="cuda", enable_registration=True, registration_method='open3d_icp'):
    """
    ä½¿ç”¨KITTIæ•°æ®æµ‹è¯•BlockWiseTransfer
    
    Args:
        data_dir: KITTIæ•°æ®æ ¹ç›®å½•
        sequence_id: åºåˆ—ID (å¦‚ "00", "01", ...)
        frame_ids: è¦æµ‹è¯•çš„å¸§IDåˆ—è¡¨ [frame_A, frame_B]
        device: è®¾å¤‡
        enable_registration: æ˜¯å¦å¯ç”¨é…å‡†
        registration_method: é…å‡†æ–¹æ³•
    """
    print(f"=== ä½¿ç”¨KITTIæ•°æ®æµ‹è¯• (åºåˆ—:{sequence_id}, å¸§:{frame_ids}) ===")
    
    # æ„å»ºæ–‡ä»¶è·¯å¾„
    velodyne_dir = os.path.join(data_dir, "sequences", sequence_id, "velodyne")
    
    frame_A_file = os.path.join(velodyne_dir, f"{frame_ids[0]:06d}.bin")
    frame_B_file = os.path.join(velodyne_dir, f"{frame_ids[1]:06d}.bin")
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(frame_A_file):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {frame_A_file}")
        return False
    if not os.path.exists(frame_B_file):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {frame_B_file}")
        return False
    
    print(f"åŠ è½½æ•°æ®:")
    print(f"  Frame A: {frame_A_file}")
    print(f"  Frame B: {frame_B_file}")
    
    try:
        # åŠ è½½åŸå§‹ç‚¹äº‘æ•°æ®
        points_A_raw = load_kitti_bin(frame_A_file)
        points_B_raw = load_kitti_bin(frame_B_file)
        
        print(f"åŸå§‹æ•°æ®:")
        print(f"  Frame A: {points_A_raw.shape}")
        print(f"  Frame B: {points_B_raw.shape}")
        
        # é¢„å¤„ç†æ•°æ® - ä½¿ç”¨å…¨å±€èŒƒå›´
        points_A_processed = preprocess_kitti_data(points_A_raw, max_points=20000)
        points_B_processed = preprocess_kitti_data(points_B_raw, max_points=15000)
        
        print(f"é¢„å¤„ç†å:")
        print(f"  Frame A: {points_A_processed.shape}")
        print(f"  Frame B: {points_B_processed.shape}")
        
        # ç‚¹äº‘é…å‡†ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if enable_registration:
            print(f"\n--- æ‰§è¡Œç‚¹äº‘é…å‡† (æ–¹æ³•: {registration_method}) ---")
            coords_A = points_A_processed[:, :3].numpy()
            coords_B = points_B_processed[:, :3].numpy()
            
            transformation, registered_coords_A, reg_info = register_point_clouds(
                coords_A, coords_B, method=registration_method
            )
            
            print(f"é…å‡†ç»“æœ:")
            print(f"  æ–¹æ³•: {reg_info['method']}")
            print(f"  é€‚åº”åº¦: {reg_info.get('fitness', 'N/A'):.4f}")
            print(f"  RMSE: {reg_info.get('inlier_rmse', 'N/A')}")
            if 'correspondence_set' in reg_info:
                print(f"  å¯¹åº”ç‚¹æ•°: {reg_info['correspondence_set']}")
            
            # æ›´æ–°Frame Açš„åæ ‡
            points_A_processed[:, :3] = torch.from_numpy(registered_coords_A).float()
            print(f"  Frame Aå·²é…å‡†åˆ°Frame Båæ ‡ç³»")
        else:
            print("âš ï¸  è·³è¿‡ç‚¹äº‘é…å‡†")
        
        # åˆ›å»ºç‰¹å¾ (Frame Aæœ‰ç‰¹å¾ï¼ŒFrame Båªæœ‰åæ ‡)
        points_A_with_features = create_features_from_kitti(points_A_processed, feature_dim=64)
        points_B_coords = points_B_processed[:, :3]  # åªå–åæ ‡
        
        # è½¬ç§»åˆ°æŒ‡å®šè®¾å¤‡
        device = torch.device(device if torch.cuda.is_available() else 'cpu')
        points_A_with_features = points_A_with_features.to(device)
        points_B_coords = points_B_coords.to(device)
        
        print(f"\næœ€ç»ˆè¾“å…¥:")
        print(f"  Frame A (with features): {points_A_with_features.shape}, device: {points_A_with_features.device}")
        print(f"  Frame B (coords only): {points_B_coords.shape}, device: {points_B_coords.device}")
        
        # === å¿«é€Ÿåæ ‡åˆ†å¸ƒç»Ÿè®¡ ===
        coords_A_for_stats = points_A_with_features[:, :3].cpu().numpy()
        coords_B_for_stats = points_B_coords.cpu().numpy()
        
        # ä½¿ç”¨æ–°çš„åˆ†æå‡½æ•°
        coord_stats = analyze_coordinate_distribution(coords_A_for_stats, coords_B_for_stats)
        print_coordinate_stats(coord_stats)
        
        # === å¼€å§‹æµ‹è¯•ä¸åŒblock_size ===
        # æµ‹è¯•ä¸åŒçš„block_size
        block_sizes = [1.0, 2.0, 5.0, 10.0]
        
        for block_size in block_sizes:
            print(f"\n--- æµ‹è¯• block_size = {block_size}m ---")
            
            model = BlockWiseTransfer(block_size=block_size)
            
            # æ‰§è¡Œå‰å‘ä¼ æ’­
            diff_coords, matched_coords_features = model(points_A_with_features, points_B_coords)
            
            total_processed = diff_coords.shape[0] + matched_coords_features.shape[0]
            
            print(f"ç»“æœ:")
            print(f"  å·®åˆ†åŒºåŸŸ: {diff_coords.shape[0]} ç‚¹ ({diff_coords.shape[0]/points_B_coords.shape[0]*100:.1f}%)")
            print(f"  åŒ¹é…åŒºåŸŸ: {matched_coords_features.shape[0]} ç‚¹ ({matched_coords_features.shape[0]/points_B_coords.shape[0]*100:.1f}%)")
            print(f"  æ€»å¤„ç†: {total_processed} / {points_B_coords.shape[0]} ç‚¹")
            print(f"  è¦†ç›–ç‡: {total_processed/points_B_coords.shape[0]*100:.1f}%")
            
            # éªŒè¯è¾“å‡ºæ ¼å¼
            assert diff_coords.shape[1] == 3, f"å·®åˆ†åæ ‡ç»´åº¦é”™è¯¯: {diff_coords.shape[1]} != 3"
            assert matched_coords_features.shape[1] == 67, f"åŒ¹é…æ•°æ®ç»´åº¦é”™è¯¯: {matched_coords_features.shape[1]} != 67"
        
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def find_kitti_sequences(data_dir):
    """æŸ¥æ‰¾å¯ç”¨çš„KITTIåºåˆ—"""
    sequences_dir = os.path.join(data_dir, "sequences")
    if not os.path.exists(sequences_dir):
        return []
    
    sequences = []
    for item in os.listdir(sequences_dir):
        seq_path = os.path.join(sequences_dir, item)
        if os.path.isdir(seq_path):
            velodyne_path = os.path.join(seq_path, "velodyne")
            if os.path.exists(velodyne_path):
                # æ£€æŸ¥æ˜¯å¦æœ‰.binæ–‡ä»¶
                bin_files = glob.glob(os.path.join(velodyne_path, "*.bin"))
                if len(bin_files) > 1:  # è‡³å°‘éœ€è¦2å¸§
                    sequences.append(item)
    
    return sorted(sequences)

def visualize_kitti_results(data_dir, sequence_id="00", frame_ids=[0, 1], device="cuda", enable_registration=True, registration_method='open3d_icp'):
    """
    å¯è§†åŒ–KITTIæ•°æ®çš„BlockWiseTransferç»“æœ
    """
    try:
        print(f"\n=== ç”ŸæˆKITTIæ•°æ®å¯è§†åŒ–ç»“æœ ===")
        
        # æ„å»ºæ–‡ä»¶è·¯å¾„
        velodyne_dir = os.path.join(data_dir, "sequences", sequence_id, "velodyne")
        frame_A_file = os.path.join(velodyne_dir, f"{frame_ids[0]:06d}.bin")
        frame_B_file = os.path.join(velodyne_dir, f"{frame_ids[1]:06d}.bin")
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(frame_A_file) or not os.path.exists(frame_B_file):
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡å¯è§†åŒ–")
            return
        
        # åŠ è½½å’Œé¢„å¤„ç†æ•°æ®ï¼ˆä½¿ç”¨è¾ƒå°çš„ç‚¹æ•°ä¾¿äºå¯è§†åŒ–ï¼‰
        points_A_raw = load_kitti_bin(frame_A_file)
        points_B_raw = load_kitti_bin(frame_B_file)
        
        # ä¸ºäº†å¯è§†åŒ–æ•ˆæœï¼Œä½¿ç”¨å…¨å±€èŒƒå›´ä½†é€‚å½“å‡å°‘ç‚¹æ•°
        points_A_processed = preprocess_kitti_data(points_A_raw, max_points=8000, 
                                                 coord_range=[(-200, 200), (-200, 200), (-10, 10)])
        points_B_processed = preprocess_kitti_data(points_B_raw, max_points=6000,
                                                 coord_range=[(-200, 200), (-200, 200), (-10, 10)])
        
        # åˆ›å»ºç‰¹å¾
        points_A_with_features = create_features_from_kitti(points_A_processed, feature_dim=64)
        points_B_coords = points_B_processed[:, :3]
        
        # ç‚¹äº‘é…å‡†ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if enable_registration:
            print(f"æ‰§è¡Œé…å‡† (æ–¹æ³•: {registration_method})")
            coords_A = points_A_processed[:, :3].numpy()
            coords_B = points_B_coords.numpy()
            
            transformation, registered_coords_A, reg_info = register_point_clouds(
                coords_A, coords_B, method=registration_method
            )
            
            print(f"é…å‡†é€‚åº”åº¦: {reg_info.get('fitness', 'N/A'):.4f}")
            
            # æ›´æ–°Frame Açš„åæ ‡
            points_A_processed[:, :3] = torch.from_numpy(registered_coords_A).float()
            points_A_with_features = create_features_from_kitti(points_A_processed, feature_dim=64)
        
        # è½¬ç§»åˆ°CPUä¾¿äºå¯è§†åŒ–
        device = torch.device('cpu')
        points_A_with_features = points_A_with_features.to(device)
        points_B_coords = points_B_coords.to(device)
        
        # æå–åæ ‡ç”¨äºå¯è§†åŒ–
        coords_A = points_A_with_features[:, :3]
        
        # æµ‹è¯•å››ç§ä¸åŒçš„block_size
        block_sizes = [1.0, 2.0, 5.0, 10.0]
        results = []
        
        for block_size in block_sizes:
            model = BlockWiseTransfer(block_size=block_size)
            diff_coords, matched_coords_features = model(points_A_with_features, points_B_coords)
            
            # æå–åŒ¹é…ç‚¹çš„åæ ‡
            if matched_coords_features.shape[0] > 0:
                matched_coords = matched_coords_features[:, :3]
            else:
                matched_coords = torch.empty((0, 3))
            
            results.append({
                'block_size': block_size,
                'diff_coords': diff_coords,
                'matched_coords': matched_coords,
                'diff_count': diff_coords.shape[0],
                'matched_count': matched_coords.shape[0]
            })
        
        # åˆ›å»ºå¤§å›¾ï¼š2x2å­å›¾å¸ƒå±€ï¼Œæ¯ä¸ªå­å›¾æ˜¾ç¤ºä¸€ç§block_sizeçš„ç»“æœ
        fig = plt.figure(figsize=(24, 20))
        
        # ä¸ºæ¯ç§block_sizeåˆ›å»ºå­å›¾
        for i, result in enumerate(results):
            # åˆ›å»ºå­å›¾ (2x2å¸ƒå±€)
            ax_main = fig.add_subplot(2, 2, i+1, projection='3d')
            
            # è½¬æ¢ä¸ºnumpyä¾¿äºç»˜å›¾
            coords_A_np = coords_A.numpy()
            coords_B_np = points_B_coords.numpy()
            diff_coords_np = result['diff_coords'].numpy()
            matched_coords_np = result['matched_coords'].numpy()
            
            # ç»˜åˆ¶åŸå§‹Frame A (è“è‰²ï¼Œè¾ƒå°ç‚¹)
            ax_main.scatter(coords_A_np[:, 0], coords_A_np[:, 1], coords_A_np[:, 2], 
                          c='lightblue', alpha=0.3, s=1, label=f'Frame A ({coords_A.shape[0]})')
            
            # ç»˜åˆ¶åŸå§‹Frame B (æµ…ç°è‰²ï¼Œè¾ƒå°ç‚¹)
            ax_main.scatter(coords_B_np[:, 0], coords_B_np[:, 1], coords_B_np[:, 2], 
                          c='lightgray', alpha=0.3, s=1, label=f'Frame B ({points_B_coords.shape[0]})')
            
            # ç»˜åˆ¶å·®åˆ†åŒºåŸŸ (çº¢è‰²ï¼Œè¾ƒå¤§ç‚¹)
            if result['diff_count'] > 0:
                ax_main.scatter(diff_coords_np[:, 0], diff_coords_np[:, 1], diff_coords_np[:, 2], 
                              c='red', alpha=0.8, s=15, label=f'Diff ({result["diff_count"]})')
            
            # ç»˜åˆ¶åŒ¹é…åŒºåŸŸ (ç»¿è‰²ï¼Œè¾ƒå¤§ç‚¹)
            if result['matched_count'] > 0:
                ax_main.scatter(matched_coords_np[:, 0], matched_coords_np[:, 1], matched_coords_np[:, 2], 
                              c='green', alpha=0.8, s=15, label=f'Matched ({result["matched_count"]})')
            
            # è®¾ç½®æ ‡é¢˜å’Œæ ‡ç­¾
            total_processed = result['diff_count'] + result['matched_count']
            coverage = total_processed / points_B_coords.shape[0] * 100
            ax_main.set_title(f'Block Size = {result["block_size"]}m\n'
                            f'Coverage: {coverage:.1f}% ({total_processed}/{points_B_coords.shape[0]})',
                            fontsize=12)
            ax_main.set_xlabel('X (m)', fontsize=10)
            ax_main.set_ylabel('Y (m)', fontsize=10)
            ax_main.set_zlabel('Z (m)', fontsize=10)
            ax_main.legend(fontsize=8)
            
            # è®¾ç½®åŠ¨æ€åæ ‡èŒƒå›´ - åŸºäºæ•°æ®è‡ªé€‚åº”è°ƒæ•´
            # è®¡ç®—å®é™…æ•°æ®èŒƒå›´
            all_coords = np.concatenate([coords_A_np, coords_B_np], axis=0)
            x_range = [all_coords[:, 0].min() - 5, all_coords[:, 0].max() + 5]
            y_range = [all_coords[:, 1].min() - 5, all_coords[:, 1].max() + 5]
            z_range = [all_coords[:, 2].min() - 1, all_coords[:, 2].max() + 1]
            
            ax_main.set_xlim(x_range)
            ax_main.set_ylim(y_range)
            ax_main.set_zlim(z_range)
            
            # è°ƒæ•´è§†è§’
            ax_main.view_init(elev=20, azim=45)
        
        plt.tight_layout()
        
        # ä¿å­˜å›¾ç‰‡
        output_path = f'/workspace/PointNeXt/kitti_blockwise_seq{sequence_id}_frames{frame_ids[0]}-{frame_ids[1]}.png'
        plt.savefig(output_path, dpi=150, bbox_inches='tight')
        print(f"å¯è§†åŒ–ç»“æœå·²ä¿å­˜åˆ°: {output_path}")
        
        # å…³é—­å›¾å½¢é‡Šæ”¾å†…å­˜
        plt.close(fig)
        
        # === æ–°å¢ï¼šç‚¹äº‘xyzè½´åˆ†å¸ƒç»Ÿè®¡å’Œå¯è§†åŒ– ===
        print(f"\n=== ç‚¹äº‘xyzè½´åˆ†å¸ƒç»Ÿè®¡ ===")
        
        # ç»Ÿè®¡Frame Aå’ŒFrame Bçš„åæ ‡åˆ†å¸ƒ
        coords_A_stats = {
            'x': {'min': coords_A_np[:, 0].min(), 'max': coords_A_np[:, 0].max(), 
                  'mean': coords_A_np[:, 0].mean(), 'std': coords_A_np[:, 0].std()},
            'y': {'min': coords_A_np[:, 1].min(), 'max': coords_A_np[:, 1].max(), 
                  'mean': coords_A_np[:, 1].mean(), 'std': coords_A_np[:, 1].std()},
            'z': {'min': coords_A_np[:, 2].min(), 'max': coords_A_np[:, 2].max(), 
                  'mean': coords_A_np[:, 2].mean(), 'std': coords_A_np[:, 2].std()}
        }
        
        coords_B_stats = {
            'x': {'min': coords_B_np[:, 0].min(), 'max': coords_B_np[:, 0].max(), 
                  'mean': coords_B_np[:, 0].mean(), 'std': coords_B_np[:, 0].std()},
            'y': {'min': coords_B_np[:, 1].min(), 'max': coords_B_np[:, 1].max(), 
                  'mean': coords_B_np[:, 1].mean(), 'std': coords_B_np[:, 1].std()},
            'z': {'min': coords_B_np[:, 2].min(), 'max': coords_B_np[:, 2].max(), 
                  'mean': coords_B_np[:, 2].mean(), 'std': coords_B_np[:, 2].std()}
        }
        
        # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
        print("Frame A åæ ‡åˆ†å¸ƒ:")
        for axis in ['x', 'y', 'z']:
            stats = coords_A_stats[axis]
            print(f"  {axis.upper()}è½´: èŒƒå›´[{stats['min']:.2f}, {stats['max']:.2f}], "
                  f"å‡å€¼:{stats['mean']:.2f}, æ ‡å‡†å·®:{stats['std']:.2f}")
        
        print("Frame B åæ ‡åˆ†å¸ƒ:")
        for axis in ['x', 'y', 'z']:
            stats = coords_B_stats[axis]
            print(f"  {axis.upper()}è½´: èŒƒå›´[{stats['min']:.2f}, {stats['max']:.2f}], "
                  f"å‡å€¼:{stats['mean']:.2f}, æ ‡å‡†å·®:{stats['std']:.2f}")
        
        # åˆ›å»ºåæ ‡åˆ†å¸ƒå¯è§†åŒ–å›¾
        fig_dist, axes = plt.subplots(3, 2, figsize=(16, 18))
        fig_dist.suptitle(f'Point Cloud Coordinate Distribution\nSequence {sequence_id}, Frames {frame_ids[0]}-{frame_ids[1]}', 
                         fontsize=16, fontweight='bold')
        
        # ä¸ºæ¯ä¸ªè½´åˆ›å»ºç›´æ–¹å›¾
        axes_names = ['X', 'Y', 'Z']
        colors = ['red', 'green', 'blue']
        
        for i, (axis_name, color) in enumerate(zip(axes_names, colors)):
            # Frame A åˆ†å¸ƒ
            ax_a = axes[i, 0]
            data_a = coords_A_np[:, i]
            ax_a.hist(data_a, bins=50, alpha=0.7, color=f'light{color}', edgecolor=color, linewidth=1)
            ax_a.axvline(data_a.mean(), color=color, linestyle='--', linewidth=2, label=f'Mean: {data_a.mean():.2f}')
            ax_a.axvline(data_a.mean() + data_a.std(), color=color, linestyle=':', alpha=0.7, 
                        label=f'Â±1Ïƒ: {data_a.std():.2f}')
            ax_a.axvline(data_a.mean() - data_a.std(), color=color, linestyle=':', alpha=0.7)
            ax_a.set_title(f'Frame A - {axis_name} Axis Distribution')
            ax_a.set_xlabel(f'{axis_name} Coordinate (m)')
            ax_a.set_ylabel('Point Count')
            ax_a.legend()
            ax_a.grid(True, alpha=0.3)
            
            # Frame B åˆ†å¸ƒ
            ax_b = axes[i, 1]
            data_b = coords_B_np[:, i]
            ax_b.hist(data_b, bins=50, alpha=0.7, color=f'light{color}', edgecolor=color, linewidth=1)
            ax_b.axvline(data_b.mean(), color=color, linestyle='--', linewidth=2, label=f'Mean: {data_b.mean():.2f}')
            ax_b.axvline(data_b.mean() + data_b.std(), color=color, linestyle=':', alpha=0.7, 
                        label=f'Â±1Ïƒ: {data_b.std():.2f}')
            ax_b.axvline(data_b.mean() - data_b.std(), color=color, linestyle=':', alpha=0.7)
            ax_b.set_title(f'Frame B - {axis_name} Axis Distribution')
            ax_b.set_xlabel(f'{axis_name} Coordinate (m)')
            ax_b.set_ylabel('Point Count')
            ax_b.legend()
            ax_b.grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        # ä¿å­˜åæ ‡åˆ†å¸ƒå›¾
        dist_path = f'/workspace/PointNeXt/kitti_coord_distribution_seq{sequence_id}_frames{frame_ids[0]}-{frame_ids[1]}.png'
        plt.savefig(dist_path, dpi=150, bbox_inches='tight')
        print(f"åæ ‡åˆ†å¸ƒå›¾å·²ä¿å­˜åˆ°: {dist_path}")
        
        plt.close(fig_dist)
        
        # åˆ›å»ºåæ ‡å¯¹æ¯”ç®±çº¿å›¾
        fig_box, axes_box = plt.subplots(1, 3, figsize=(18, 6))
        fig_box.suptitle(f'Coordinate Distribution Comparison (Box Plot)\nSequence {sequence_id}, Frames {frame_ids[0]}-{frame_ids[1]}', 
                        fontsize=14, fontweight='bold')
        
        for i, (axis_name, color) in enumerate(zip(axes_names, colors)):
            ax = axes_box[i]
            data_to_plot = [coords_A_np[:, i], coords_B_np[:, i]]
            labels = [f'Frame A\n({coords_A_np.shape[0]} pts)', f'Frame B\n({coords_B_np.shape[0]} pts)']
            
            box_plot = ax.boxplot(data_to_plot, labels=labels, patch_artist=True)
            box_plot['boxes'][0].set_facecolor(f'light{color}')
            box_plot['boxes'][1].set_facecolor(f'light{color}')
            box_plot['boxes'][0].set_alpha(0.7)
            box_plot['boxes'][1].set_alpha(0.7)
            
            ax.set_title(f'{axis_name} Axis Distribution')
            ax.set_ylabel(f'{axis_name} Coordinate (m)')
            ax.grid(True, alpha=0.3)
            
            # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯æ–‡æœ¬
            stats_text = f'Frame A: Î¼={coords_A_stats[axis_name.lower()]["mean"]:.2f}, Ïƒ={coords_A_stats[axis_name.lower()]["std"]:.2f}\n'
            stats_text += f'Frame B: Î¼={coords_B_stats[axis_name.lower()]["mean"]:.2f}, Ïƒ={coords_B_stats[axis_name.lower()]["std"]:.2f}'
            ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, fontsize=9, 
                   verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))
        
        plt.tight_layout()
        
        # ä¿å­˜ç®±çº¿å›¾
        box_path = f'/workspace/PointNeXt/kitti_coord_boxplot_seq{sequence_id}_frames{frame_ids[0]}-{frame_ids[1]}.png'
        plt.savefig(box_path, dpi=150, bbox_inches='tight')
        print(f"åæ ‡ç®±çº¿å›¾å·²ä¿å­˜åˆ°: {box_path}")
        
        # === åŸæœ‰çš„ç»Ÿè®¡å¯¹æ¯”å›¾éƒ¨åˆ† ===
        # åˆ›å»ºç»Ÿè®¡å¯¹æ¯”å›¾
        fig2, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
        
        # æå–ç»Ÿè®¡æ•°æ®
        block_sizes_list = [r['block_size'] for r in results]
        diff_counts = [r['diff_count'] for r in results]
        matched_counts = [r['matched_count'] for r in results]
        total_counts = [d + m for d, m in zip(diff_counts, matched_counts)]
        coverage_rates = [t / points_B_coords.shape[0] * 100 for t in total_counts]
        
        # å›¾1: å„block_sizeçš„ç‚¹æ•°åˆ†å¸ƒ
        x = np.arange(len(block_sizes_list))
        width = 0.35
        
        ax1.bar(x - width/2, diff_counts, width, label='Diff Points', color='red', alpha=0.7)
        ax1.bar(x + width/2, matched_counts, width, label='Matched Points', color='green', alpha=0.7)
        ax1.set_xlabel('Block Size (m)')
        ax1.set_ylabel('Point Count')
        ax1.set_title('Point Distribution by Block Size')
        ax1.set_xticks(x)
        ax1.set_xticklabels(block_sizes_list)
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # å›¾2: è¦†ç›–ç‡å¯¹æ¯”
        ax2.plot(block_sizes_list, coverage_rates, 'b-o', linewidth=2, markersize=8)
        ax2.set_xlabel('Block Size (m)')
        ax2.set_ylabel('Coverage Rate (%)')
        ax2.set_title('Coverage Rate vs Block Size')
        ax2.grid(True, alpha=0.3)
        ax2.set_ylim([0, 100])
        
        # å›¾3: é¥¼å›¾æ˜¾ç¤ºæœ€ä¼˜block_sizeçš„åˆ†å¸ƒ
        best_idx = np.argmax(coverage_rates)
        best_result = results[best_idx]
        labels = ['Diff Points', 'Matched Points']
        sizes = [best_result['diff_count'], best_result['matched_count']]
        colors = ['red', 'green']
        
        # åªæ˜¾ç¤ºéé›¶çš„éƒ¨åˆ†
        non_zero_data = [(label, size, color) for label, size, color in zip(labels, sizes, colors) if size > 0]
        if non_zero_data:
            non_zero_labels, non_zero_sizes, non_zero_colors = zip(*non_zero_data)
            wedges, texts, autotexts = ax3.pie(non_zero_sizes, labels=non_zero_labels, 
                                              colors=non_zero_colors, autopct='%1.1f%%', startangle=90)
            ax3.set_title(f'Best Block Size: {best_result["block_size"]}m\n'
                         f'Coverage: {coverage_rates[best_idx]:.1f}%')
        
        # å›¾4: å¤„ç†æ•ˆç‡å¯¹æ¯”
        efficiency = [m / (d + m) * 100 if (d + m) > 0 else 0 for d, m in zip(diff_counts, matched_counts)]
        ax4.bar(block_sizes_list, efficiency, color='orange', alpha=0.7)
        ax4.set_xlabel('Block Size (m)')
        ax4.set_ylabel('Matching Efficiency (%)')
        ax4.set_title('Matching Efficiency by Block Size')
        ax4.grid(True, alpha=0.3)
        ax4.set_ylim([0, 100])
        
        plt.tight_layout()
        
        # ä¿å­˜ç»Ÿè®¡å›¾
        stats_path = f'/workspace/PointNeXt/kitti_blockwise_stats_seq{sequence_id}_frames{frame_ids[0]}-{frame_ids[1]}.png'
        plt.savefig(stats_path, dpi=150, bbox_inches='tight')
        print(f"ç»Ÿè®¡å›¾å·²ä¿å­˜åˆ°: {stats_path}")
        
        plt.close(fig2)
        
        # ç”Ÿæˆè¯¦ç»†çš„æ–‡æœ¬æŠ¥å‘Š
        report_path = f'/workspace/PointNeXt/kitti_blockwise_report_seq{sequence_id}_frames{frame_ids[0]}-{frame_ids[1]}.txt'
        with open(report_path, 'w') as f:
            f.write("KITTI BlockWiseTransfer æµ‹è¯•æŠ¥å‘Š\n")
            f.write("=" * 60 + "\n\n")
            f.write(f"æ•°æ®é›†ä¿¡æ¯:\n")
            f.write(f"  åºåˆ—ID: {sequence_id}\n")
            f.write(f"  æµ‹è¯•å¸§: {frame_ids[0]} -> {frame_ids[1]}\n")
            f.write(f"  Frame A: {coords_A.shape[0]} ç‚¹, ç‰¹å¾ç»´åº¦: 64\n")
            f.write(f"  Frame B: {points_B_coords.shape[0]} ç‚¹\n\n")
            
            # æ·»åŠ xyzè½´åˆ†å¸ƒç»Ÿè®¡
            f.write("ç‚¹äº‘åæ ‡åˆ†å¸ƒç»Ÿè®¡:\n")
            f.write("-" * 60 + "\n")
            f.write("Frame A åæ ‡åˆ†å¸ƒ:\n")
            for axis in ['x', 'y', 'z']:
                stats = coords_A_stats[axis]
                f.write(f"  {axis.upper()}è½´: èŒƒå›´[{stats['min']:.2f}, {stats['max']:.2f}], "
                       f"å‡å€¼:{stats['mean']:.2f}, æ ‡å‡†å·®:{stats['std']:.2f}\n")
            
            f.write("\nFrame B åæ ‡åˆ†å¸ƒ:\n")
            for axis in ['x', 'y', 'z']:
                stats = coords_B_stats[axis]
                f.write(f"  {axis.upper()}è½´: èŒƒå›´[{stats['min']:.2f}, {stats['max']:.2f}], "
                       f"å‡å€¼:{stats['mean']:.2f}, æ ‡å‡†å·®:{stats['std']:.2f}\n")
            
            # æ·»åŠ åæ ‡åç§»åˆ†æ
            f.write("\nåæ ‡åç§»åˆ†æ:\n")
            for axis in ['x', 'y', 'z']:
                offset_mean = coords_B_stats[axis]['mean'] - coords_A_stats[axis]['mean']
                offset_std = abs(coords_B_stats[axis]['std'] - coords_A_stats[axis]['std'])
                f.write(f"  {axis.upper()}è½´åç§»: å‡å€¼å·®={offset_mean:.2f}m, æ ‡å‡†å·®å·®={offset_std:.2f}m\n")
            f.write("\n")
            
            f.write("å„Block Sizeæµ‹è¯•ç»“æœ:\n")
            f.write("-" * 60 + "\n")
            for i, result in enumerate(results):
                total = result['diff_count'] + result['matched_count']
                coverage = total / points_B_coords.shape[0] * 100
                efficiency = result['matched_count'] / total * 100 if total > 0 else 0
                
                f.write(f"Block Size {result['block_size']}m:\n")
                f.write(f"  å·®åˆ†åŒºåŸŸ: {result['diff_count']} ç‚¹ ({result['diff_count']/points_B_coords.shape[0]*100:.1f}%)\n")
                f.write(f"  åŒ¹é…åŒºåŸŸ: {result['matched_count']} ç‚¹ ({result['matched_count']/points_B_coords.shape[0]*100:.1f}%)\n")
                f.write(f"  æ€»å¤„ç†: {total} / {points_B_coords.shape[0]} ç‚¹\n")
                f.write(f"  è¦†ç›–ç‡: {coverage:.1f}%\n")
                f.write(f"  åŒ¹é…æ•ˆç‡: {efficiency:.1f}%\n\n")
            
            # æ¨èæœ€ä½³å‚æ•°
            best_coverage_idx = np.argmax(coverage_rates)
            best_efficiency_idx = np.argmax(efficiency)
            
            f.write("æ¨èå‚æ•°:\n")
            f.write(f"  æœ€ä½³è¦†ç›–ç‡: Block Size {results[best_coverage_idx]['block_size']}m (è¦†ç›–ç‡: {coverage_rates[best_coverage_idx]:.1f}%)\n")
            f.write(f"  æœ€ä½³åŒ¹é…æ•ˆç‡: Block Size {results[best_efficiency_idx]['block_size']}m (åŒ¹é…æ•ˆç‡: {efficiency[best_efficiency_idx]:.1f}%)\n")
        
        print(f"è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")
        
    except ImportError:
        print("æœªå®‰è£…matplotlibï¼Œè·³è¿‡å¯è§†åŒ–")
        print("å¦‚éœ€å¯è§†åŒ–ï¼Œè¯·å®‰è£…: pip install matplotlib")
    except Exception as e:
        print(f"å¯è§†åŒ–è¿‡ç¨‹å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()

def register_point_clouds(source_points, target_points, method='open3d_icp', **kwargs):
    """
    ç‚¹äº‘é…å‡†ç»Ÿä¸€æ¥å£
    
    Args:
        source_points: (N, 3) numpy array - æºç‚¹äº‘åæ ‡
        target_points: (M, 3) numpy array - ç›®æ ‡ç‚¹äº‘åæ ‡
        method: é…å‡†æ–¹æ³• ['open3d_icp', 'open3d_feature', 'simple_icp', 'none']
        **kwargs: å…¶ä»–å‚æ•°
    
    Returns:
        transformation_matrix: (4, 4) å˜æ¢çŸ©é˜µ
        registered_points: é…å‡†åçš„æºç‚¹äº‘
        registration_info: é…å‡†ä¿¡æ¯å­—å…¸
    """
    if method == 'none':
        # ä¸è¿›è¡Œé…å‡†ï¼Œè¿”å›å•ä½çŸ©é˜µ
        identity = np.eye(4)
        return identity, source_points.copy(), {'method': 'none', 'fitness': 1.0}
    
    elif method == 'open3d_icp' and HAS_OPEN3D:
        return register_with_open3d_icp(source_points, target_points, **kwargs)
    
    elif method == 'open3d_feature' and HAS_OPEN3D:
        return register_with_open3d_feature(source_points, target_points, **kwargs)
    
    elif method == 'simple_icp':
        return register_with_simple_icp(source_points, target_points, **kwargs)
    
    else:
        print(f"âš ï¸  é…å‡†æ–¹æ³• '{method}' ä¸å¯ç”¨ï¼Œä½¿ç”¨ç®€å•ICP")
        return register_with_simple_icp(source_points, target_points, **kwargs)

def register_with_open3d_icp(source_points, target_points, threshold=2.0, max_iteration=50):
    """ä½¿ç”¨Open3D ICPé…å‡†"""
    # åˆ›å»ºç‚¹äº‘å¯¹è±¡
    source = o3d.geometry.PointCloud()
    target = o3d.geometry.PointCloud()
    source.points = o3d.utility.Vector3dVector(source_points)
    target.points = o3d.utility.Vector3dVector(target_points)
    
    # ä¼°è®¡æ³•å‘é‡
    source.estimate_normals()
    target.estimate_normals()
    
    # ICPé…å‡†
    reg_result = o3d.pipelines.registration.registration_icp(
        source, target, threshold,
        estimation_method=o3d.pipelines.registration.TransformationEstimationPointToPoint(),
        criteria=o3d.pipelines.registration.ICPConvergenceCriteria(max_iteration=max_iteration)
    )
    
    # åº”ç”¨å˜æ¢
    source.transform(reg_result.transformation)
    registered_points = np.asarray(source.points)
    
    info = {
        'method': 'open3d_icp',
        'fitness': reg_result.fitness,
        'inlier_rmse': reg_result.inlier_rmse,
        'correspondence_set': len(reg_result.correspondence_set)
    }
    
    return reg_result.transformation, registered_points, info

def register_with_open3d_feature(source_points, target_points, 
                                 voxel_size=1.0, distance_threshold=1.5):
    """ä½¿ç”¨Open3DåŸºäºç‰¹å¾çš„é…å‡†"""
    # åˆ›å»ºç‚¹äº‘å¯¹è±¡
    source = o3d.geometry.PointCloud()
    target = o3d.geometry.PointCloud()
    source.points = o3d.utility.Vector3dVector(source_points)
    target.points = o3d.utility.Vector3dVector(target_points)
    
    # ä¸‹é‡‡æ ·
    source_down = source.voxel_down_sample(voxel_size)
    target_down = target.voxel_down_sample(voxel_size)
    
    # è®¡ç®—æ³•å‘é‡
    radius_normal = voxel_size * 2
    source_down.estimate_normals(o3d.geometry.KDTreeSearchParamHybrid(radius=radius_normal, max_nn=30))
    target_down.estimate_normals(o3d.geometry.KDTreeSearchParamHybrid(radius=radius_normal, max_nn=30))
    
    # è®¡ç®—FPFHç‰¹å¾
    radius_feature = voxel_size * 5
    source_fpfh = o3d.pipelines.registration.compute_fpfh_feature(
        source_down, o3d.geometry.KDTreeSearchParamHybrid(radius=radius_feature, max_nn=100))
    target_fpfh = o3d.pipelines.registration.compute_fpfh_feature(
        target_down, o3d.geometry.KDTreeSearchParamHybrid(radius=radius_feature, max_nn=100))
    
    # RANSACé…å‡†
    reg_result = o3d.pipelines.registration.registration_ransac_based_on_feature_matching(
        source_down, target_down, source_fpfh, target_fpfh, True, distance_threshold,
        o3d.pipelines.registration.TransformationEstimationPointToPoint(False), 3,
        [o3d.pipelines.registration.CorrespondenceCheckerBasedOnEdgeLength(0.9),
         o3d.pipelines.registration.CorrespondenceCheckerBasedOnDistance(distance_threshold)],
        o3d.pipelines.registration.RANSACConvergenceCriteria(100000, 0.999))
    
    # ç²¾ç»†é…å‡†
    reg_result = o3d.pipelines.registration.registration_icp(
        source, target, distance_threshold, reg_result.transformation,
        o3d.pipelines.registration.TransformationEstimationPointToPoint())
    
    # åº”ç”¨å˜æ¢
    source.transform(reg_result.transformation)
    registered_points = np.asarray(source.points)
    
    info = {
        'method': 'open3d_feature',
        'fitness': reg_result.fitness,
        'inlier_rmse': reg_result.inlier_rmse,
        'correspondence_set': len(reg_result.correspondence_set)
    }
    
    return reg_result.transformation, registered_points, info

def register_with_simple_icp(source_points, target_points, max_iterations=20, tolerance=1e-6):
    """ç®€å•çš„ICPå®ç°ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰"""
    if not HAS_SCIPY:
        print("âš ï¸  SciPyæœªå®‰è£…ï¼Œä½¿ç”¨æœ€ç®€å•çš„é…å‡†æ–¹æ¡ˆ")
        # ä½¿ç”¨è´¨å¿ƒå¯¹é½ä½œä¸ºæœ€ç®€å•çš„é…å‡†
        source_center = np.mean(source_points, axis=0)
        target_center = np.mean(target_points, axis=0)
        translation = target_center - source_center
        
        # æ„å»ºå˜æ¢çŸ©é˜µ
        transformation = np.eye(4)
        transformation[:3, 3] = translation
        
        # åº”ç”¨å˜æ¢
        registered_points = source_points + translation
        
        info = {
            'method': 'centroid_alignment',
            'fitness': 0.5,  # å‡è®¾é€‚åº”åº¦
            'inlier_rmse': np.linalg.norm(translation),
            'success': True
        }
        
        return transformation, registered_points, info
    
    def transformation_matrix_from_params(params):
        """ä»6DOFå‚æ•°æ„å»ºå˜æ¢çŸ©é˜µ"""
        tx, ty, tz, rx, ry, rz = params
        
        # æ—‹è½¬çŸ©é˜µï¼ˆæ¬§æ‹‰è§’ï¼‰
        cx, sx = np.cos(rx), np.sin(rx)
        cy, sy = np.cos(ry), np.sin(ry)
        cz, sz = np.cos(rz), np.sin(rz)
        
        R = np.array([
            [cy*cz, -cy*sz, sy],
            [sx*sy*cz + cx*sz, -sx*sy*sz + cx*cz, -sx*cy],
            [-cx*sy*cz + sx*sz, cx*sy*sz + sx*cz, cx*cy]
        ])
        
        T = np.eye(4)
        T[:3, :3] = R
        T[:3, 3] = [tx, ty, tz]
        return T
    
    def objective_function(params, source, target):
        """ç›®æ ‡å‡½æ•°ï¼šæœ€å°åŒ–ç‚¹åˆ°ç‚¹è·ç¦»"""
        T = transformation_matrix_from_params(params)
        source_transformed = (T[:3, :3] @ source.T + T[:3, 3:4]).T
        
        # è®¡ç®—æœ€è¿‘é‚»è·ç¦»
        distances = cdist(source_transformed, target)
        min_distances = np.min(distances, axis=1)
        return np.mean(min_distances)
    
    # åˆå§‹å‚æ•°ä¼°è®¡
    source_center = np.mean(source_points, axis=0)
    target_center = np.mean(target_points, axis=0)
    initial_translation = target_center - source_center
    initial_params = np.concatenate([initial_translation, [0, 0, 0]])
    
    # ä¼˜åŒ–
    result = minimize(objective_function, initial_params, 
                     args=(source_points, target_points),
                     method='L-BFGS-B')
    
    # æ„å»ºæœ€ç»ˆå˜æ¢çŸ©é˜µ
    final_transformation = transformation_matrix_from_params(result.x)
    
    # åº”ç”¨å˜æ¢
    source_homo = np.hstack([source_points, np.ones((len(source_points), 1))])
    registered_points = (final_transformation @ source_homo.T).T[:, :3]
    
    info = {
        'method': 'simple_icp',
        'fitness': 1.0 / (1.0 + result.fun),  # è¿‘ä¼¼é€‚åº”åº¦
        'inlier_rmse': result.fun,
        'success': result.success
    }
    
    return final_transformation, registered_points, info

def get_best_registration_method():
    """
    æ ¹æ®å¯ç”¨åº“è‡ªåŠ¨é€‰æ‹©æœ€ä½³é…å‡†æ–¹æ³•
    """
    if HAS_OPEN3D:
        print("ğŸ¯ ä½¿ç”¨Open3D ICPé…å‡†ï¼ˆé«˜ç²¾åº¦ï¼‰")
        return 'open3d_icp'
    elif HAS_SCIPY:
        print("ğŸ¯ ä½¿ç”¨ç®€å•ICPé…å‡†ï¼ˆä¸­ç­‰ç²¾åº¦ï¼‰")
        return 'simple_icp'
    else:
        print("ğŸ¯ ä½¿ç”¨è´¨å¿ƒå¯¹é½é…å‡†ï¼ˆåŸºç¡€ç²¾åº¦ï¼‰")
        return 'simple_icp'  # è´¨å¿ƒå¯¹é½åœ¨simple_icpä¸­å¤„ç†

def main():
    print("å¼€å§‹KITTIæ•°æ®æµ‹è¯•...")
    
    # KITTIæ•°æ®è·¯å¾„é…ç½®
    # è¯·æ ¹æ®æ‚¨çš„å®é™…è·¯å¾„ä¿®æ”¹
    possible_data_dirs = [
        "/workspace/network/data/kitti",  # ç”¨æˆ·æä¾›çš„è·¯å¾„
        "/workspace/data/kitti",
        "/workspace/datasets/kitti", 
        "/data/kitti",
        "/datasets/kitti",
        "./kitti_data",
        "../kitti_data"
    ]
    
    data_dir = None
    for path in possible_data_dirs:
        if os.path.exists(path):
            data_dir = path
            break
    
    if data_dir is None:
        print("âŒ æœªæ‰¾åˆ°KITTIæ•°æ®é›†ï¼Œè¯·æ£€æŸ¥ä»¥ä¸‹è·¯å¾„æ˜¯å¦å­˜åœ¨:")
        for path in possible_data_dirs:
            print(f"  {path}")
        print("\nè¯·ç¡®ä¿KITTIæ•°æ®é›†ç»“æ„å¦‚ä¸‹:")
        print("kitti_data/")
        print("â”œâ”€â”€ sequences/")
        print("â”‚   â”œâ”€â”€ 00/")
        print("â”‚   â”‚   â””â”€â”€ velodyne/")
        print("â”‚   â”‚       â”œâ”€â”€ 000000.bin")
        print("â”‚   â”‚       â”œâ”€â”€ 000001.bin")
        print("â”‚   â”‚       â””â”€â”€ ...")
        print("â”‚   â”œâ”€â”€ 01/")
        print("â”‚   â””â”€â”€ ...")
        return
    
    print(f"æ‰¾åˆ°KITTIæ•°æ®é›†: {data_dir}")
    
    # æŸ¥æ‰¾å¯ç”¨åºåˆ—
    sequences = find_kitti_sequences(data_dir)
    if not sequences:
        print(f"âŒ åœ¨ {data_dir} ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆçš„KITTIåºåˆ—")
        return
    
    print(f"å¯ç”¨åºåˆ—: {sequences}")
    
    # è‡ªåŠ¨é€‰æ‹©æœ€ä½³é…å‡†æ–¹æ³•
    best_registration_method = get_best_registration_method()
    
    # æµ‹è¯•å‰å‡ ä¸ªåºåˆ—
    test_sequences = sequences[:2]  # æµ‹è¯•å‰2ä¸ªåºåˆ—
    
    for seq_id in test_sequences:
        print(f"\n{'='*50}")
        
        # æµ‹è¯•è¿ç»­å¸§
        frame_pairs = [(0, 1), (10, 11), (50, 51)]
        
        for frame_A, frame_B in frame_pairs:
            success = test_with_kitti_data(
                data_dir=data_dir,
                sequence_id=seq_id,
                frame_ids=[frame_A, frame_B],
                device="cuda",
                enable_registration=True,  # å¯ç”¨é…å‡†
                registration_method=best_registration_method  # è‡ªåŠ¨é€‰æ‹©æœ€ä½³æ–¹æ³•
            )
            
            if not success:
                print(f"è·³è¿‡åºåˆ— {seq_id} çš„å¸§ {frame_A}-{frame_B}")
                continue
            
            # ç”Ÿæˆå¯è§†åŒ–
            visualize_kitti_results(
                data_dir=data_dir,
                sequence_id=seq_id,
                frame_ids=[frame_A, frame_B],
                device="cuda",
                enable_registration=True,
                registration_method=best_registration_method  # ä½¿ç”¨ç›¸åŒçš„é…å‡†æ–¹æ³•
            )
            
            break  # æˆåŠŸæµ‹è¯•ä¸€å¯¹å¸§åè·³å‡º
    
    print(f"\nğŸ‰ KITTIæ•°æ®æµ‹è¯•å®Œæˆ!")

if __name__ == "__main__":
    main()

def analyze_coordinate_distribution(coords_A, coords_B, frame_names=['Frame A', 'Frame B']):
    """
    åˆ†æä¸¤ä¸ªç‚¹äº‘çš„åæ ‡åˆ†å¸ƒ
    
    Args:
        coords_A: (N, 3) numpy array - ç¬¬ä¸€ä¸ªç‚¹äº‘çš„åæ ‡
        coords_B: (M, 3) numpy array - ç¬¬äºŒä¸ªç‚¹äº‘çš„åæ ‡
        frame_names: ä¸¤ä¸ªç‚¹äº‘çš„åç§°
    
    Returns:
        stats_dict: åŒ…å«ç»Ÿè®¡ä¿¡æ¯çš„å­—å…¸
    """
    stats = {}
    
    for i, (coords, name) in enumerate(zip([coords_A, coords_B], frame_names)):
        stats[name] = {}
        for j, axis in enumerate(['x', 'y', 'z']):
            stats[name][axis] = {
                'min': float(coords[:, j].min()),
                'max': float(coords[:, j].max()),
                'mean': float(coords[:, j].mean()),
                'std': float(coords[:, j].std()),
                'range': float(coords[:, j].max() - coords[:, j].min())
            }
    
    # è®¡ç®—åæ ‡åç§»
    stats['offset'] = {}
    for axis in ['x', 'y', 'z']:
        stats['offset'][axis] = {
            'mean_diff': stats[frame_names[1]][axis]['mean'] - stats[frame_names[0]][axis]['mean'],
            'std_diff': stats[frame_names[1]][axis]['std'] - stats[frame_names[0]][axis]['std'],
            'range_diff': stats[frame_names[1]][axis]['range'] - stats[frame_names[0]][axis]['range']
        }
    
    return stats

def print_coordinate_stats(stats, frame_names=['Frame A', 'Frame B']):
    """
    æ‰“å°åæ ‡ç»Ÿè®¡ä¿¡æ¯
    
    Args:
        stats: analyze_coordinate_distributionè¿”å›çš„ç»Ÿè®¡å­—å…¸
        frame_names: å¸§åç§°åˆ—è¡¨
    """
    print("=== åæ ‡åˆ†å¸ƒç»Ÿè®¡ ===")
    
    for name in frame_names:
        print(f"\n{name} åæ ‡åˆ†å¸ƒ:")
        for axis in ['x', 'y', 'z']:
            s = stats[name][axis]
            print(f"  {axis.upper()}è½´: èŒƒå›´[{s['min']:.2f}, {s['max']:.2f}] ({s['range']:.2f}m), "
                  f"å‡å€¼:{s['mean']:.2f}, æ ‡å‡†å·®:{s['std']:.2f}")
    
    print("\nåæ ‡åç§»åˆ†æ:")
    for axis in ['x', 'y', 'z']:
        offset = stats['offset'][axis]
        print(f"  {axis.upper()}è½´åç§»: å‡å€¼å·®={offset['mean_diff']:.2f}m, "
              f"æ ‡å‡†å·®å·®={offset['std_diff']:.2f}m, èŒƒå›´å·®={offset['range_diff']:.2f}m")
